{
    "docs": [
        {
            "location": "/",
            "text": "Warning\n\n\nrdbc project and this documentation is still a work in progress.\nIt's not ready yet for production use.\n\n\n\n\nWhat is rdbc?\n\u00b6\n\n\nrdbc is a SQL-level relational database connectivity API targeting Scala and \nJava programming languages. The API is fully asynchronous and provides\na possibility to leverage \nReactive Streams'\n\nstream processing capabilities.\n\n\nGoals\n\u00b6\n\n\nFollowing list outlines the goals of the API:\n\n\n\n\n\n\nProvide vendor neutral access to most commonly used database features.\n\n\nThe API is meant to be vendor neutral in a sense that if clients stick\nto using only standard SQL features no vendor-specific code should be needed\nand database backends can be switched with no client code changes.\n\n\n\n\n\n\nBe asynchronous and reactive.\n\n\nAll methods that can potentially perform I/O actions don't block the executing\nthread so the API fits well into a non-blocking application design. rdbc\nallows building applications according to the \nReactive Manifesto\n\nby using \nReactive Streams\n for asynchronous\nresults streaming with a back-pressure.\n\n\n\n\n\n\nProvide a foundation for higher-level APIs.\n\n\nrdbc is a rather low-level API enabling clients to use plain SQL queries\nand get results back. While it can be used directly it's also meant to \nprovide a foundation for higher-level APIs like functional or object\nrelational mapping libraries.\n\n\n\n\n\n\nNon-goals\n\u00b6\n\n\nFollowing list outlines the areas that the API is not meant to cover.\n\n\n\n\n\n\nProvide a full type-safety.\n\n\nrdbc works on a SQL level, meaning that requests made to the database\nare strings. There is no additional layer that would ensure type-safety\nwhen working with SQL. The API is also meant to be dynamic and allow type\nconverters to be registered at runtime. This approach sacrifices some\ntype-safety but at the same time makes it possible to implement wider range\nof higher-level APIs on top of rdbc.\n\n\n\n\n\n\nGetting help\n\u00b6\n\n\nJoin \nrdbc-io/rdbc\n gitter channel for \nquestions and any kind of discussion about rdbc. You are also free to\nask your question by creating a Github \nissue\n.\n\n\nSee also \nrdbc\n\ntag on StackOverflow.\n\n\nLicense\n\u00b6\n\n\nrdbc is an open source software licensed under\n\nApache License 2.0\n.",
            "title": "Introduction"
        },
        {
            "location": "/#what-is-rdbc",
            "text": "rdbc is a SQL-level relational database connectivity API targeting Scala and \nJava programming languages. The API is fully asynchronous and provides\na possibility to leverage  Reactive Streams' \nstream processing capabilities.",
            "title": "What is rdbc?"
        },
        {
            "location": "/#goals",
            "text": "Following list outlines the goals of the API:    Provide vendor neutral access to most commonly used database features.  The API is meant to be vendor neutral in a sense that if clients stick\nto using only standard SQL features no vendor-specific code should be needed\nand database backends can be switched with no client code changes.    Be asynchronous and reactive.  All methods that can potentially perform I/O actions don't block the executing\nthread so the API fits well into a non-blocking application design. rdbc\nallows building applications according to the  Reactive Manifesto \nby using  Reactive Streams  for asynchronous\nresults streaming with a back-pressure.    Provide a foundation for higher-level APIs.  rdbc is a rather low-level API enabling clients to use plain SQL queries\nand get results back. While it can be used directly it's also meant to \nprovide a foundation for higher-level APIs like functional or object\nrelational mapping libraries.",
            "title": "Goals"
        },
        {
            "location": "/#non-goals",
            "text": "Following list outlines the areas that the API is not meant to cover.    Provide a full type-safety.  rdbc works on a SQL level, meaning that requests made to the database\nare strings. There is no additional layer that would ensure type-safety\nwhen working with SQL. The API is also meant to be dynamic and allow type\nconverters to be registered at runtime. This approach sacrifices some\ntype-safety but at the same time makes it possible to implement wider range\nof higher-level APIs on top of rdbc.",
            "title": "Non-goals"
        },
        {
            "location": "/#getting-help",
            "text": "Join  rdbc-io/rdbc  gitter channel for \nquestions and any kind of discussion about rdbc. You are also free to\nask your question by creating a Github  issue .  See also  rdbc \ntag on StackOverflow.",
            "title": "Getting help"
        },
        {
            "location": "/#license",
            "text": "rdbc is an open source software licensed under Apache License 2.0 .",
            "title": "License"
        },
        {
            "location": "/scala/gettingstarted/",
            "text": "Warning\n\n\nrdbc project and this documentation is still a work in progress.\nIt's not ready yet for production use.\n\n\n\n\nAdding rdbc to your project\n\u00b6\n\n\nrdbc is just an API \u2014 to actually use it as a database client you need\nan implementation called a driver. So \u2014 to use rdbc in your project you need\nto include \ntwo\n dependencies, one for the API, and one for a driver. This \ndocumentation doesn't describe any particular driver \u2014 you should be able to\nfind artifact names you need to include in your build definition in the driver's\ndocumentation. For your convenience, however, \nDrivers\n page lists available\ndrivers grouped by a database engine they support.\n\n\nrdbc JARs are published to\n\nMaven Central\n\nrepository. The API is currently available for Scala 2.11 and 2.12 and requires\nJava 8 runtime.\n\n\nSBT\n\u00b6\n\n\nFor sbt projects, add the following to \nbuild.sbt\n:\n\n\nlibraryDependencies\n \n++=\n \nVector\n(\n\n  \n\"io.rdbc\"\n \n%%\n \n\"rdbc-api-scala\"\n \n%\n \n\"{{version}}\"\n,\n\n  \n//here goes the driver dependency\n\n\n)\n\n\n\n\n\n\nGradle\n\u00b6\n\n\nFor Gradle projects, add the following to the \ndependencies\n section of \nbuild.gradle\n:\n\n\nScala 2.12\n\n\ncompile\n \ngroup:\n \n'io.rdbc'\n,\n \nname:\n \n'rdbc-api-scala_2.12'\n,\n \nversion:\n \n'{{version}}'\n\n\ncompile\n \n//here goes the driver dependency\n\n\n\n\n\n\nScala 2.11\n\n\ncompile\n \ngroup:\n \n'io.rdbc'\n,\n \nname:\n \n'rdbc-api-scala_2.11'\n,\n \nversion:\n \n'{{version}}'\n\n\ncompile\n \n//here goes the driver dependency\n\n\n\n\n\n\nMaven\n\u00b6\n\n\nFor Maven projects, add the following to the \ndependencies\n element of \npom.xml\n:\n\n\nScala 2.12\n\n\n<dependency>\n\n  \n<groupId>\nio.rdbc\n</groupId>\n\n  \n<artifactId>\nrdbc-api-scala_2.12\n</artifactId>\n\n  \n<version>\n{{version}}\n</version>\n\n\n</dependency>\n\n\n<dependency>\n\n  \n<!-- here goes the driver dependency -->\n\n\n</dependency>\n\n\n\n\n\n\nScala 2.11\n\n\n<dependency>\n\n  \n<groupId>\nio.rdbc\n</groupId>\n\n  \n<artifactId>\nrdbc-api-scala_2.11\n</artifactId>\n\n  \n<version>\n{{version}}\n</version>\n\n\n</dependency>\n\n\n<dependency>\n\n  \n<!-- here goes the driver dependency -->\n\n\n</dependency>\n\n\n\n\n\n\nWorking with Scala \nFuture\ns\n\u00b6\n\n\nSince all rdbc API methods that perform I/O return Scala's \nFuture\ns you'll\nneed a knowledge on how to write asynchronous code using them. Throughout this \ndocumentation it is assumed that the reader has a basic knowledge about \nFuture\n\ntrait. If you're new to this concept you may find these resources useful:\n\n\n\n\nThe Neophyte's Guide to Scala\n\n\nOfficial documentation\n\n\n\n\nA \"Hello world\" application\n\u00b6\n\n\nIt's time for a small but complete example of rdbc API usage. A snippet below\ninserts a \"Hello world!\" greeting into a \nmessages\n database table. \n\n\nA table with the following definition is assumed to exist:\n\n\ncreate\n \ntable\n \nmessages\n(\ntxt\n \nvarchar\n(\n100\n))\n\n\n\n\n\n\nAnd here's the actual code snippet:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\nimport\n \nio.rdbc.sapi._\n\n\n\nimport\n \nscala.concurrent.ExecutionContext.Implicits.global\n\n\nimport\n \nscala.concurrent.duration._\n\n\nimport\n \nscala.concurrent.\n{\nAwait\n,\n \nFuture\n}\n\n\nimport\n \nscala.util.\n{\nFailure\n,\n \nSuccess\n}\n\n\n\nobject\n \nHelloRdbc\n \nextends\n \nApp\n \n{\n\n\n  \nval\n \nconnFactory\n:\n \nConnectionFactory\n \n=\n \n???\n\n\n  \nval\n \ngreeting\n \n=\n \n\"Hello World!\"\n\n  \nval\n \ninsertFut\n:\n \nFuture\n[\nLong\n]\n \n=\n \nconnFactory\n.\nwithConnection\n \n{\n \nconn\n \n=>\n\n    \nconn\n\n      \n.\nstatement\n(\nsql\n\"insert into messages(txt) values ($greeting)\"\n)\n\n      \n.\nflatMap\n(\nstmt\n \n=>\n \nstmt\n.\nexecuteForRowsAffected\n())\n\n  \n}.\nandThen\n \n{\n\n    \ncase\n \nSuccess\n(\ncount\n)\n \n=>\n \nprintln\n(\ns\"inserted \n$count\n greeting(s)\"\n)\n\n    \ncase\n \nFailure\n(\nex\n)\n \n=>\n \nex\n.\nprintStackTrace\n()\n\n  \n}\n\n\n  \nAwait\n.\nready\n(\n\n    \ninsertFut\n.\ntransformWith\n(\n_\n \n=>\n \nconnFactory\n.\nshutdown\n()),\n\n    \n10.\nseconds\n\n  \n)\n\n\n}\n\n\n\n\n\n\n\nIn this very simple application:\n\n\n\n\n\n\nAt line \n10\n a\n   \nConnectionFactory\n\n   coming from a driver package should be instantiated. Each rdbc driver provides\n   an implementation of this trait that allows to estabilish a connection to a database.\n   \nConnectionFactory\n implementation and classes needed for its configuration should\n   be the only classes directly used from the driver package.\n\n\n\n\n\n\nAt line \n13\n a connection to the database is requested to be estabilished - \n   when that happens, a function passed as a code block is executed.\n\n\n\n\n\n\nIn this code block, at line \n15\n a prepared statement is requested to be\n   created using a\n   \nsql\n\n   \nstring interpolator\n\n   which passes a \ngreeting\n string argument to it.\n\n\n\n\n\n\nWhen the statement is ready, it is requested to be executed at line \n16\n and\n   to return number of affected rows.\n\n\n\n\n\n\nWhen the database operation finishes and the connection is released, at line\n   \n17\n the \nFuture\n's result is handled: number of affected rows is printed in\n   case of a success or a stack trace is printed in case of an error.\n\n\n\n\n\n\nNone of the database calls block the executing thread - all of them return\n   \nFuture\ns that are then chained. The only statement that blocks starts at line\n   \n22\n when the application waits for operations requested earlier to complete.\n   Because this demo is just a simple console application, we need to block the\n   thread somewhere to wait for a moment that the application can exit.\n\n\n\n\n\n\nScaladoc\n\u00b6\n\n\nYou can browse Scaladoc using javadoc.io site \n\nhere\n. The site\nallows to switch between Scala versions and rdbc versions.",
            "title": "Getting started"
        },
        {
            "location": "/scala/gettingstarted/#adding-rdbc-to-your-project",
            "text": "rdbc is just an API \u2014 to actually use it as a database client you need\nan implementation called a driver. So \u2014 to use rdbc in your project you need\nto include  two  dependencies, one for the API, and one for a driver. This \ndocumentation doesn't describe any particular driver \u2014 you should be able to\nfind artifact names you need to include in your build definition in the driver's\ndocumentation. For your convenience, however,  Drivers  page lists available\ndrivers grouped by a database engine they support.  rdbc JARs are published to Maven Central \nrepository. The API is currently available for Scala 2.11 and 2.12 and requires\nJava 8 runtime.",
            "title": "Adding rdbc to your project"
        },
        {
            "location": "/scala/gettingstarted/#sbt",
            "text": "For sbt projects, add the following to  build.sbt :  libraryDependencies   ++=   Vector ( \n   \"io.rdbc\"   %%   \"rdbc-api-scala\"   %   \"{{version}}\" , \n   //here goes the driver dependency  )",
            "title": "SBT"
        },
        {
            "location": "/scala/gettingstarted/#gradle",
            "text": "For Gradle projects, add the following to the  dependencies  section of  build.gradle :  Scala 2.12  compile   group:   'io.rdbc' ,   name:   'rdbc-api-scala_2.12' ,   version:   '{{version}}'  compile   //here goes the driver dependency   Scala 2.11  compile   group:   'io.rdbc' ,   name:   'rdbc-api-scala_2.11' ,   version:   '{{version}}'  compile   //here goes the driver dependency",
            "title": "Gradle"
        },
        {
            "location": "/scala/gettingstarted/#maven",
            "text": "For Maven projects, add the following to the  dependencies  element of  pom.xml :  Scala 2.12  <dependency> \n   <groupId> io.rdbc </groupId> \n   <artifactId> rdbc-api-scala_2.12 </artifactId> \n   <version> {{version}} </version>  </dependency>  <dependency> \n   <!-- here goes the driver dependency -->  </dependency>   Scala 2.11  <dependency> \n   <groupId> io.rdbc </groupId> \n   <artifactId> rdbc-api-scala_2.11 </artifactId> \n   <version> {{version}} </version>  </dependency>  <dependency> \n   <!-- here goes the driver dependency -->  </dependency>",
            "title": "Maven"
        },
        {
            "location": "/scala/gettingstarted/#working-with-scala-futures",
            "text": "Since all rdbc API methods that perform I/O return Scala's  Future s you'll\nneed a knowledge on how to write asynchronous code using them. Throughout this \ndocumentation it is assumed that the reader has a basic knowledge about  Future \ntrait. If you're new to this concept you may find these resources useful:   The Neophyte's Guide to Scala  Official documentation",
            "title": "Working with Scala Futures"
        },
        {
            "location": "/scala/gettingstarted/#a-hello-world-application",
            "text": "It's time for a small but complete example of rdbc API usage. A snippet below\ninserts a \"Hello world!\" greeting into a  messages  database table.   A table with the following definition is assumed to exist:  create   table   messages ( txt   varchar ( 100 ))   And here's the actual code snippet:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26 import   io.rdbc.sapi._  import   scala.concurrent.ExecutionContext.Implicits.global  import   scala.concurrent.duration._  import   scala.concurrent. { Await ,   Future }  import   scala.util. { Failure ,   Success }  object   HelloRdbc   extends   App   { \n\n   val   connFactory :   ConnectionFactory   =   ??? \n\n   val   greeting   =   \"Hello World!\" \n   val   insertFut :   Future [ Long ]   =   connFactory . withConnection   {   conn   => \n     conn \n       . statement ( sql \"insert into messages(txt) values ($greeting)\" ) \n       . flatMap ( stmt   =>   stmt . executeForRowsAffected ()) \n   }. andThen   { \n     case   Success ( count )   =>   println ( s\"inserted  $count  greeting(s)\" ) \n     case   Failure ( ex )   =>   ex . printStackTrace () \n   } \n\n   Await . ready ( \n     insertFut . transformWith ( _   =>   connFactory . shutdown ()), \n     10. seconds \n   )  }    In this very simple application:    At line  10  a\n    ConnectionFactory \n   coming from a driver package should be instantiated. Each rdbc driver provides\n   an implementation of this trait that allows to estabilish a connection to a database.\n    ConnectionFactory  implementation and classes needed for its configuration should\n   be the only classes directly used from the driver package.    At line  13  a connection to the database is requested to be estabilished - \n   when that happens, a function passed as a code block is executed.    In this code block, at line  15  a prepared statement is requested to be\n   created using a\n    sql \n    string interpolator \n   which passes a  greeting  string argument to it.    When the statement is ready, it is requested to be executed at line  16  and\n   to return number of affected rows.    When the database operation finishes and the connection is released, at line\n    17  the  Future 's result is handled: number of affected rows is printed in\n   case of a success or a stack trace is printed in case of an error.    None of the database calls block the executing thread - all of them return\n    Future s that are then chained. The only statement that blocks starts at line\n    22  when the application waits for operations requested earlier to complete.\n   Because this demo is just a simple console application, we need to block the\n   thread somewhere to wait for a moment that the application can exit.",
            "title": "A \"Hello world\" application"
        },
        {
            "location": "/scala/gettingstarted/#scaladoc",
            "text": "You can browse Scaladoc using javadoc.io site  here . The site\nallows to switch between Scala versions and rdbc versions.",
            "title": "Scaladoc"
        },
        {
            "location": "/scala/core_concepts/",
            "text": "Warning\n\n\nrdbc project and this documentation is still a work in progress.\nIt's not ready yet for production use.\n\n\n\n\nThere are a couple of core concepts that the API is built upon:\n\n\n\n\n\n\nAsynchronous processing\n\n\nEvery operation that involves I/O with the database is asynchronous. Methods\n return \nFuture\n or Reactive Stream's \nPublisher\n instances.\n\n\n\n\n\n\nThread safety\n\n\nrdbc API requires that its implementations must be thread-safe. You are free\n to share class instances among threads, even those that are mutable.\n\n\n\n\n\n\nNull safety\n\n\nSQL \nNULL\n values are represented as \nOption\n instances. Scala \nnull\n doesn't\n have to be used when working with the API.\n\n\n\n\n\n\nLimiting execution time\n\n\nSo that application doesn't \"hang\" forever, operations that interact with\n the database accept a mandatory \nimplicit\n \nTimeout\n instance which\n controls maximum processing time.",
            "title": "Core concepts"
        },
        {
            "location": "/scala/connection/",
            "text": "Warning\n\n\nrdbc project and this documentation is still a work in progress.\nIt's not ready yet for production use.\n\n\n\n\nConnecting to a database\n\u00b6\n\n\nTo connect to a database you first need to get a hold on \nConnectionFactory\n\nimplementation provided by a rdbc driver. Consult the driver's documentation on how to\ninstantiate and configure \nConnectionFactory\n it provides. \n\n\nTo connect to a database means to obtain \nConnection\n instance. Once you have\nthe factory, you have the following options on how to get the connection:\n\n\nManually opening and releasing a connection\n\u00b6\n\n\nConnection factory provides \nconnection\n method that simply returns a \nFuture\n\nholding a \nConnection\n. A connection obtained this way must be then released\nmanually using \nrelease\n method. Here's the example usage:\n\n\nimport\n \nio.rdbc.sapi._\n\n\nimport\n \nio.rdbc.util.Futures._\n\n\n\nval\n \ncf\n:\n \nConnectionFactory\n \n=\n \n???\n\n\n\nval\n \nresult\n \n=\n \ncf\n.\nconnect\n().\nflatMap\n \n{\n \nconn\n \n=>\n\n   \n/* use the connection */\n\n   \n???\n\n\n}.\nandThenF\n \n{\n \ncase\n \n_\n \n=>\n\n   \nconn\n.\nrelease\n()\n\n\n}\n\n\n\n\n\n\nandThenF\n future combinator provided by \nrdbc utilities\n package\nis like a standard \nandThen\n but partial function passed to it returns a \nFuture\n and\nthe chain can proceed only when this future completes. Relation between\n\nandThenF\n and \nandThen\n is analogous to the relation between \nflatMap\n and \nmap\n.\n\n\nUsing the loan pattern\n\u00b6\n\n\nEven if you haven't heard about the loan pattern you probably know what it is.\nConnection factory provides \nwithConnection\n method that executes a block\nof code in the context of a database connection and releases the connection\nafterwards. It looks like this:\n\n\nimport\n \nio.rdbc.sapi._\n\n\n\nval\n \ncf\n:\n \nConnectionFactory\n \n=\n \n???\n\n\n\nval\n \nresult\n \n=\n \ncf\n.\nwithConnection\n \n{\n \nconn\n \n=>\n\n   \n/* use the connection */\n\n   \n???\n\n\n}\n\n\n\n\n\n\nThe above example is equivalent to the one from the\n\nprevious paragraph\n.\n\n\nTODO\n how to use loan pattern with streaming? Introduce a stream that closes\nthe connection on stream completion, cancellation or error\n\n\nTransaction management\n\u00b6\n\n\nIn rdbc, \nConnection\n provides facilities to manage database transactions. Using SQL\nto manage transaction state by issuing commands like \nBEGIN\n or \nROLLBACK\n is\nnot allowed. If you don't manage transaction at all, every SQL statement will\nbe executed in its own transaction. Following sections describe ways of managing\ntransactions.\n\n\nManual\n\u00b6\n\n\nManaging transaction manually means using the three methods provided by \nConnection\n\ntrait: \nbeginTx\n, \ncommitTx\n and \nrollbackTx\n. Each of these methods\nreturn a \nFuture\n of \nUnit\n \u2014 there is no dedicated trait or class representing\na transaction. Similar to manual handling of connecting and disconnecting from\nthe database, manual transaction management is kind of cumbersome. When you\ndon't need the flexibility provided by the three methods, use the transactional\nloan pattern described below.\n\n\nUsing the transactional loan pattern\n\u00b6\n\n\nConnection\n trait provides \nwithTransaction\n method which allows to execute\na block of code in a context of a newly started transaction. If a \nFuture\n returned\nby the block of code is successful, the transaction will be committed \u2014 if\nit fails, the transaction will be rolled back:\n\n\nimport\n \nio.rdbc.sapi._\n\n\n\nval\n \ncf\n:\n \nConnectionFactory\n \n=\n \n???\n\n\n\nval\n \nresult\n \n=\n \ncf\n.\nwithConnection\n \n{\n \nconn\n \n=>\n\n   \nconn\n.\nwithTransaction\n \n{\n\n    \n/* use the connection in a context of the transaction */\n\n    \n???\n\n   \n}\n\n\n}\n\n\n\n\n\n\nIf any error occurs when rolling back the transaction, this error will be reported\nto the execution context and the original error causing the rollback will be returned.\n\n\nIt's a common use case to connect to the database and execute just a single\ntransaction. This use case is covered by \nwithTransaction\n method\nprovided by a \nConnectionFactory\n. Above snippet could be simplified as follows:\n\n\nimport\n \nio.rdbc.sapi._\n\n\n\nval\n \ncf\n:\n \nConnectionFactory\n \n=\n \n???\n\n\n\nval\n \nresult\n \n=\n \ncf\n.\nwithTransaction\n \n{\n \nconn\n \n=>\n\n    \n/* use the connection in a context of the transaction */\n\n    \n???\n\n\n}\n\n\n\n\n\n\nValidation\n\u00b6\n\n\nSometimes, it may be useful to verify whether already open connection is \"valid\",\ni.e. whether it can still execute queries. A connection may get broken because of\na number of reasons including network-related problems. To check whether the connection\nis usable, use a \nvalidate\n method which returns a \nFuture\n of \nBoolean\n.\n\n\nConnection can also be validated by executing any query but using \nvalidate\n is\na preferred way since it can leverage a vendor-specific way of validating the\nconnection with a minimal overhead.\n\n\nConcurrent operations\n\u00b6\n\n\nAs every other rdbc class, \nConnection\n is thread-safe. However, it doesn't mean\nthat multiple threads can execute queries using the same connection at the same\ntime. Only one operation can be executed at any given time. When some thread tries\nto use a non-idle connection, resulting \nFuture\n fails with\n\nIllegalSessionStateException\n.\nException to this rule is \n\nforceRelease\n\nmethod which can be used regardless of whether connection is idle or not.\n\n\nExample below demonstrates an invalid code which can fail with \nIllegalSessionStateException\n:\n\n\n1\n2\n3\n4\n5\n6\n7\n8\nimport\n \nio.rdbc.sapi._\n\n\n\nval\n \ncf\n:\n \nConnectionFactory\n \n=\n \n???\n\n\n\ncf\n.\nwithConnection\n \n{\n \nconn\n \n=>\n\n    \nconn\n.\nvalidate\n().\nforeach\n(\nvalid\n \n=>\n \nprintln\n(\ns\"1. valid = \n$valid\n\"\n))\n\n\n    \nconn\n.\nvalidate\n().\nforeach\n(\nvalid\n \n=>\n \nprintln\n(\ns\"2. valid = \n$valid\n\"\n))\n\n\n}\n\n\n\n\n\n\n\nFuture\n returned by statement at line \n7\n may fail because connection may still\nbe busy executing a request from line \n6\n. You can be sure though that the connection\nwill start executing the first request (line \n6\n) before the second (line \n7\n)\n\u2014 there is a happens-before relation there.\n\n\nTo make the above code safe, it could be rewritten like this:\n\n\nimport\n \nio.rdbc.sapi._\n\n\n\nval\n \ncf\n:\n \nConnectionFactory\n \n=\n \n???\n\n\n\ncf\n.\nwithConnection\n \n{\n \nconn\n \n=>\n\n    \nconn\n.\nvalidate\n().\nforeach\n(\nvalid\n \n=>\n \nprintln\n(\ns\"1. valid = \n$valid\n\"\n))\n\n    \n.\nandThen\n \n{\n \n_\n \n=>\n\n       \nconn\n.\nvalidate\n().\nforeach\n(\nvalid\n \n=>\n \nprintln\n(\ns\"2. valid = \n$valid\n\"\n))\n\n    \n}\n\n\n}\n\n\n\n\n\n\nConnection\n also provides \nwatchForIdle\n method returning future which\ncompletes when connection becomes idle. Snippet below is safe from failing\nwith \nIllegalSessionStateException\n.\n\n\nimport\n \nio.rdbc.sapi._\n\n\n\nval\n \ncf\n:\n \nConnectionFactory\n \n=\n \n???\n\n\n\ncf\n.\nwithConnection\n \n{\n \nconn\n \n=>\n\n    \nconn\n.\nvalidate\n().\nforeach\n(\nvalid\n \n=>\n \nprintln\n(\ns\"1. valid = \n$valid\n\"\n))\n\n    \nconn\n.\nwatchForIdle\n.\nandThen\n \n{\n \n_\n \n=>\n\n        \nconn\n.\nvalidate\n().\nforeach\n(\nvalid\n \n=>\n \nprintln\n(\ns\"2. valid = \n$valid\n\"\n))\n\n    \n}\n\n\n}\n\n\n\n\n\n\nConnection pooling\n\u00b6\n\n\nEstabilishing a new connection every time an interaction with the database is needed\nis expensive performance-wise. There usually is an overhead of initializing\nnew session. In order to avoid this problem you can use connection pooling.\n\n\nConnection pooling mechanism isn't really part of the API \u2014 to use pooling\nyou just need to use a special \nConnectionFactory\n implementation.\n\n\nHave a look at \nrdbc-pool\n project that\nprovides a \nConnectionFactory\n implementation capable of connection pooling.",
            "title": "Working with a connection"
        },
        {
            "location": "/scala/connection/#connecting-to-a-database",
            "text": "To connect to a database you first need to get a hold on  ConnectionFactory \nimplementation provided by a rdbc driver. Consult the driver's documentation on how to\ninstantiate and configure  ConnectionFactory  it provides.   To connect to a database means to obtain  Connection  instance. Once you have\nthe factory, you have the following options on how to get the connection:",
            "title": "Connecting to a database"
        },
        {
            "location": "/scala/connection/#manually-opening-and-releasing-a-connection",
            "text": "Connection factory provides  connection  method that simply returns a  Future \nholding a  Connection . A connection obtained this way must be then released\nmanually using  release  method. Here's the example usage:  import   io.rdbc.sapi._  import   io.rdbc.util.Futures._  val   cf :   ConnectionFactory   =   ???  val   result   =   cf . connect (). flatMap   {   conn   => \n    /* use the connection */ \n    ???  }. andThenF   {   case   _   => \n    conn . release ()  }   andThenF  future combinator provided by  rdbc utilities  package\nis like a standard  andThen  but partial function passed to it returns a  Future  and\nthe chain can proceed only when this future completes. Relation between andThenF  and  andThen  is analogous to the relation between  flatMap  and  map .",
            "title": "Manually opening and releasing a connection"
        },
        {
            "location": "/scala/connection/#using-the-loan-pattern",
            "text": "Even if you haven't heard about the loan pattern you probably know what it is.\nConnection factory provides  withConnection  method that executes a block\nof code in the context of a database connection and releases the connection\nafterwards. It looks like this:  import   io.rdbc.sapi._  val   cf :   ConnectionFactory   =   ???  val   result   =   cf . withConnection   {   conn   => \n    /* use the connection */ \n    ???  }   The above example is equivalent to the one from the previous paragraph .  TODO  how to use loan pattern with streaming? Introduce a stream that closes\nthe connection on stream completion, cancellation or error",
            "title": "Using the loan pattern"
        },
        {
            "location": "/scala/connection/#transaction-management",
            "text": "In rdbc,  Connection  provides facilities to manage database transactions. Using SQL\nto manage transaction state by issuing commands like  BEGIN  or  ROLLBACK  is\nnot allowed. If you don't manage transaction at all, every SQL statement will\nbe executed in its own transaction. Following sections describe ways of managing\ntransactions.",
            "title": "Transaction management"
        },
        {
            "location": "/scala/connection/#manual",
            "text": "Managing transaction manually means using the three methods provided by  Connection \ntrait:  beginTx ,  commitTx  and  rollbackTx . Each of these methods\nreturn a  Future  of  Unit  \u2014 there is no dedicated trait or class representing\na transaction. Similar to manual handling of connecting and disconnecting from\nthe database, manual transaction management is kind of cumbersome. When you\ndon't need the flexibility provided by the three methods, use the transactional\nloan pattern described below.",
            "title": "Manual"
        },
        {
            "location": "/scala/connection/#using-the-transactional-loan-pattern",
            "text": "Connection  trait provides  withTransaction  method which allows to execute\na block of code in a context of a newly started transaction. If a  Future  returned\nby the block of code is successful, the transaction will be committed \u2014 if\nit fails, the transaction will be rolled back:  import   io.rdbc.sapi._  val   cf :   ConnectionFactory   =   ???  val   result   =   cf . withConnection   {   conn   => \n    conn . withTransaction   { \n     /* use the connection in a context of the transaction */ \n     ??? \n    }  }   If any error occurs when rolling back the transaction, this error will be reported\nto the execution context and the original error causing the rollback will be returned.  It's a common use case to connect to the database and execute just a single\ntransaction. This use case is covered by  withTransaction  method\nprovided by a  ConnectionFactory . Above snippet could be simplified as follows:  import   io.rdbc.sapi._  val   cf :   ConnectionFactory   =   ???  val   result   =   cf . withTransaction   {   conn   => \n     /* use the connection in a context of the transaction */ \n     ???  }",
            "title": "Using the transactional loan pattern"
        },
        {
            "location": "/scala/connection/#validation",
            "text": "Sometimes, it may be useful to verify whether already open connection is \"valid\",\ni.e. whether it can still execute queries. A connection may get broken because of\na number of reasons including network-related problems. To check whether the connection\nis usable, use a  validate  method which returns a  Future  of  Boolean .  Connection can also be validated by executing any query but using  validate  is\na preferred way since it can leverage a vendor-specific way of validating the\nconnection with a minimal overhead.",
            "title": "Validation"
        },
        {
            "location": "/scala/connection/#concurrent-operations",
            "text": "As every other rdbc class,  Connection  is thread-safe. However, it doesn't mean\nthat multiple threads can execute queries using the same connection at the same\ntime. Only one operation can be executed at any given time. When some thread tries\nto use a non-idle connection, resulting  Future  fails with IllegalSessionStateException .\nException to this rule is  forceRelease \nmethod which can be used regardless of whether connection is idle or not.  Example below demonstrates an invalid code which can fail with  IllegalSessionStateException :  1\n2\n3\n4\n5\n6\n7\n8 import   io.rdbc.sapi._  val   cf :   ConnectionFactory   =   ???  cf . withConnection   {   conn   => \n     conn . validate (). foreach ( valid   =>   println ( s\"1. valid =  $valid \" ))       conn . validate (). foreach ( valid   =>   println ( s\"2. valid =  $valid \" ))  }    Future  returned by statement at line  7  may fail because connection may still\nbe busy executing a request from line  6 . You can be sure though that the connection\nwill start executing the first request (line  6 ) before the second (line  7 )\n\u2014 there is a happens-before relation there.  To make the above code safe, it could be rewritten like this:  import   io.rdbc.sapi._  val   cf :   ConnectionFactory   =   ???  cf . withConnection   {   conn   => \n     conn . validate (). foreach ( valid   =>   println ( s\"1. valid =  $valid \" )) \n     . andThen   {   _   => \n        conn . validate (). foreach ( valid   =>   println ( s\"2. valid =  $valid \" )) \n     }  }   Connection  also provides  watchForIdle  method returning future which\ncompletes when connection becomes idle. Snippet below is safe from failing\nwith  IllegalSessionStateException .  import   io.rdbc.sapi._  val   cf :   ConnectionFactory   =   ???  cf . withConnection   {   conn   => \n     conn . validate (). foreach ( valid   =>   println ( s\"1. valid =  $valid \" )) \n     conn . watchForIdle . andThen   {   _   => \n         conn . validate (). foreach ( valid   =>   println ( s\"2. valid =  $valid \" )) \n     }  }",
            "title": "Concurrent operations"
        },
        {
            "location": "/scala/connection/#connection-pooling",
            "text": "Estabilishing a new connection every time an interaction with the database is needed\nis expensive performance-wise. There usually is an overhead of initializing\nnew session. In order to avoid this problem you can use connection pooling.  Connection pooling mechanism isn't really part of the API \u2014 to use pooling\nyou just need to use a special  ConnectionFactory  implementation.  Have a look at  rdbc-pool  project that\nprovides a  ConnectionFactory  implementation capable of connection pooling.",
            "title": "Connection pooling"
        },
        {
            "location": "/scala/statements/",
            "text": "Warning\n\n\nrdbc project and this documentation is still a work in progress.\nIt's not ready yet for production use.\n\n\n\n\nStatement types\n\u00b6\n\n\nStatements are a core feature of rdbc API. They represent SQL pieces that are sent\nto a database for execution along with arguments, if any. There are two types\nof statements in rdbc: template statements and executable statements. Template\nstatements can't be executed right away. To execute them you first need to bind argument\nfor every parameter they declare. When filled with arguments, template statements\ncreate executable statements. Statements in rdbc are a representation database engine's\n\nprepared statements\n.\n\n\nSyntax\n\u00b6\n\n\nThere isn't much of a syntax to describe. The only thing in a statement syntax\nthat rdbc adds to SQL is how parameters are defined. There are two kinds of\nparameters: named and positional.\n\n\nNamed parameters\n\u00b6\n\n\nNamed parameters:\n\n\n\n\nare alphanumeric identifiers,\n\n\ncan be defined inside a query by prepending parameter identifier with a colon,\n\n\ncan be placed only where database engine expects parameters as defined\n     by a database engine's prepared statement syntax,\n\n\nare ignored inside varchar literals, column aliases, comments, etc.,\n\n\ncan be referenced by their name or by index (position).\n\n\n\n\nIn the following statement just one parameter is declared: \nlogin\n:\n\n\nselect\n \n*\n \nfrom\n \nusers\n \nwhere\n \nusername\n \n=\n \n:\nlogin\n\n\n\n\n\n\nA parameter can be used in multiple places. Statement below defines a single\nparameter: \nname\n, but this parameter is used in two places:\n\n\nselect\n \n*\n \nfrom\n \nusers\n \nwhere\n \nfirst_name\n \n=\n \n:\nname\n \nor\n \nmiddle_name\n \n=\n \n:\nname\n \n\n\n\n\n\nThe statement below doesn't declare any parameters. \"fname\" is inside a varchar\nliteral and \"mname\" is part of a comment.\n\n\nselect\n \n*\n \nfrom\n \nusers\n \nwhere\n \nfirst_name\n \n=\n \n':fname'\n \n-- or middle_name = :mname\n\n\n\n\n\n\nPositional parameters\n\u00b6\n\n\nPositional parameters:\n\n\n\n\ncan be defined inside a query by placing a question mark: \n?\n,\n\n\ncan be placed only where database engine expects parameters as defined\n     by a database engine's prepared statement syntax,\n\n\nare ignored inside varchar literals, column aliases, comments, etc.,\n\n\ncan be referenced only by their index (position).\n\n\n\n\nThe following example statement uses two positional parameters:\n\n\nselect\n \n*\n \nfrom\n \nusers\n \nwhere\n \nfirst_name\n \n=\n \n?\n \nor\n \nmiddle_name\n \n=\n \n?\n \n\n\n\n\n\nThe statement below doesn't declare any parameters. The first question mark is \ninside a varchar literal and the second is part of a comment.\n\n\nselect\n \n*\n \nfrom\n \nusers\n \nwhere\n \nfirst_name\n \n=\n \n'?'\n \n-- or middle_name = ?\n\n\n\n\n\n\nCreating statements\n\u00b6\n\n\nBare strings\n\u00b6\n\n\nStatement can be created using a bare string and then in a separate step be\nfilled with arguments for execution. There is a \nstatement\n method defined in \nConnection\n\ntrait that accepts a string, and returns a \nStatement\n instance bound to the\nconnection:\n\n\nval\n \nstmt\n:\n \nStatement\n \n=\n \nconn\n.\nstatement\n(\n\n \n\"select * from users \"\n \n+\n\n \n\"where (first_name = :name or last_name = :name) and age = :age\"\n\n\n)\n\n\n\n\n\n\nOnce you have a \nStatement\n object, you can bind values to its parameters:\n\n\n\n\n\n\nby name\n\n\nTo bind values to parameters by name, use \nStatement\n's \nbind\n method that\naccepts a sequence of \n(String, Any)\n tuples, one for each parameter. Above\nstatement's parameters could be bound to values like this:\n\nstmt\n.\nbind\n(\n\"name\"\n \n->\n \n\"Casey\"\n,\n \n\"age\"\n \n->\n \n30\n)\n.\n\n\nIf you don't provide all parameter values when binding, a \nMissingParamValException\n\nwill be thrown. If you provide value for a parameter that wasn't declared by\nthe query, \nNoSuchParamException\n will be thrown.\n\n\nBinding by name is available only if name parameters were used.\n\n\n\n\n\n\nby index\n\n\nThere is a possibility to bind values to parameters by index - i.e. just\nprovide a list of values and these values will be matched to every parameter\noccurrence. Arguments can be bound to the above query like this:\n\nstmt\n.\nbind\n(\n\"Casey\"\n,\n \n\"Casey\"\n,\n \n30\n)\n.\n\n\nIf you provide too many parameters \nTooManyParamsException\n will be thrown.\nIf you provide too few parameters \nMissingParamValException\n will be thrown.\n\n\nThis method of binding is the only one available if you used positional parameters.\n\n\n\n\n\n\nTODO describe what to do with statements without parameters.\n\n\nString interpolator\n\u00b6\n\n\nCreating statements using simple strings and binding values to parameters in\na separate step is flexible but this flexibility is not really needed in most\ncases. A preferred way of creating statements is by using \nsql\n\n\nstring interpolator\n.\n\n\nYou can get \nsql\n interpolator into scope either by importing everything from\n\nio.rdbc.sapi\n package by \nimport\n \nio.rdbc.sapi._\n statement or selectively by\n\nimport\n \nio.rdbc.sapi.SqlInterpolator._\n statement.\n\n\nOnce you have it in scope, you can use it to declare parameters and bind values\nto them in one step, like this:\n\n\nval\n \nconn\n:\n \nConnection\n \n=\n \n???\n\n\n\ndef\n \nfindUsersStmt\n(\nname\n:\n \nString\n)\n:\n \nExecutableStatement\n \n=\n \n{\n\n   \nconn\n.\nstatement\n(\nsql\n\"select * from users where name = $name\"\n)\n\n\n}\n\n\n\n\n\n\nAs you can see, when \nsql\n interpolator is used \nConnection\n's \nstatement\n method\nproduces \nExecutableStatement\n, so the statement already has values\nbound to its parameters. The above example is equivalent to the following, somewhat\nless concise snippet:\n\n\ndef\n \nfindUsersStmt\n(\nname\n:\n \nString\n)\n:\n \nExecutableStatement\n \n=\n \n{\n   \n    \nconn\n.\nstatement\n(\n\"select * from users where name = ?\"\n)\n\n        \n.\nbindByIdx\n(\nname\n)\n\n\n}\n\n\n\n\n\n\nSQL parts created by \nsql\n interpolator can be concatenated in the same way you\nwould concatenate plain strings:\n\n\ndef\n \nfindUsersStmt\n(\nname\n:\n \nString\n,\n \nage\n:\n \nInt\n)\n:\n \nExecutableStatement\n \n=\n \n{\n\n  \nconn\n.\nstatement\n(\n\n   \nsql\n\"select * from users \"\n \n+\n\n   \nsql\n\"where (first_name = $name or last_name = $name) and age = $age\"\n\n  \n)\n\n\n}\n\n\n\n\n\n\nImportant thing to understand is that when using \nsql\n interpolator you're still\nsafe from creating SQL injection vulnerability. Parameter values are \nnot\n passed\nin to the database as literals concatenated with the rest of the SQL.\n\n\nDynamic SQL\n\u00b6\n\n\nSometimes, most notably in tests or some one-time use scripts, it may be useful\nto create SQL dynamically, like this:\n\n\ndef\n \nstmt\n(\ntable\n:\n \nString\n,\n \nname\n:\n \nString\n)\n:\n \nFutureExecutableStatement\n \n=\n \n{\n\n  \nconn\n.\nstatement\n(\ns\"select * from \n$table\n where name = :name\"\n)\n\n      \n.\nbind\n(\n\"name\"\n \n->\n \nname\n)\n\n\n}\n\n\n\n\n\n\nIf you want to create SQL dynamically and still benefit from \nsql\n interpolator\nfeatures, use \n#$\n prefix for dynamic parts, like this:\n\n\ndef\n \nsql\n(\ntable\n:\n \nString\n,\n \nname\n:\n \nString\n)\n:\n \nExecutableStatement\n \n=\n \n{\n\n  \nconn\n.\nstatement\n(\nsql\n\"select * from #$table where name = $name\"\n)\n\n\n}\n\n\n\n\n\n\nIn the above example, only \n$name\n is a statement parameter, \n#$table\n will be\nsimply replaced by \ntable\n method parameter value.\n\n\nOptions\n\u00b6\n\n\nWhen creating a statement you can provide options that can tweak statement's\nbehavior. To pass options, use \nConnection\n's \nstatement\n methods that accept\nsecond argument of \nStatementOptions\n type.\n\n\nThe list below contains currently supported options:\n\n\n\n\n\n\n\n\nOption:\n \ngeneratedKeyCols\n\n\nControls statement behavior regarding returning keys generated by the\n database when issuing update or insert statements.\n\n\nPossible values\n:\n\n\n\n\nKeyColumns.All\n \u2014 all columns with generated keys will be returned\n\n\nKeyColumns.None\n \u2014 no columns with generated keys will be returned\n\n\nKeyColumns.named(cols: String*)\n \u2014 only columns listed by name will be returned\n\n\n\n\nDefault value\n: \nKeyColumns.None\n\n\n\n\n\n\n\n\nStatementOptions\n is a case class and in its companion object there is \nDefault\n\ninstance of it with the default option values. You can use this instance to\ntweak only some of the options using built-in \ncopy\n method:\n\n\nconn\n.\nstatement\n(\n\n  \nsql\n\"insert into users(name) values ($name)\"\n,\n\n  \nDefault\n.\ncopy\n(\noption1\n \n=\n \nvalue1\n,\n \noption2\n \n=\n \nvalue2\n)\n\n\n)\n\n\n\n\n\n\nExecuting statements\n\u00b6\n\n\nOnce you have an \nExecutableStatement\n instance, you can execute it in a couple\nof different ways. The method of execution controls in what shape you get the\nresults from the database. Paragraphs below describe methods of executing statements.\n\n\nExecuting for a result set\n\u00b6\n\n\nArguably the simplest method of execution that returns results is to execute\nstatement for a result set. To do this, use \nExecutableStatement\n's\n\nexecuteForSet\n method that returns \nFuture\n of \nResultSet\n.\n\n\nResultSet\n gives you access to the rows as well as to the metadata like warnings\nissued by the DB engine, columns metadata and count of rows affected by the statement.\nIt also implements \nTraversable\n trait providing a convenience method of traversing\nthrough the rows.\n\n\nExecuting for set is simple, but be aware that for bigger sets you may encounter\n\nOutOfMemoryError\ns. All results are stored in memory, there is no paging of any\nkind. If you want to avoid this sort of problems, consider\n\nstreaming\n the results.\n\n\nFor the documentation on how to work with the resulting rows see\n\nResult Rows\n chapter.\n\n\nTODO example\n\n\nStreaming results\n\u00b6\n\n\nTo stream results from the database, use \nExecutableStatement\n's \nstream\n\nmethod. This method returns \nRowPublisher\n instance which implements\nreactive stream's \nPublisher\n interface. Items published are rows represented\nby \nRow\n trait. For the documentation on how to work with the resulting rows see\n\nResult Rows\n chapter.\n\n\nHere are a couple of things to know when working with streams:\n\n\n\n\nstatement execution is deferred until publisher is subscribed to,\n\n\na publisher can be subscribed to only once,\n\n\nafter \nstream\n method is invoked, connection is considered busy and can be used\n     for other queries only after the stream completes or is cancelled,\n\n\ncancel is an asynchronous operation and reactive streams specification doesn't\n     provide a way of notifying a client that cancel operation completed. If clients\n     want to use the connection after stream cancellation, they must watch for\n     connection's \nwatchForIdle\n \nFuture\n completion before requesting any\n     subsequent operations.\n\n\n\n\nProcessing streams is out of scope of this manual, for details please refer to\ndocumentation of libraries that are built to facilitate this, like\n\nAkka stream\n or \nMonix\n.\n\n\nTODO describe how to release connection after stream completion\n\n\nTODO example\n\n\nExecuting ignoring results\n\u00b6\n\n\nIn many cases clients are not interested in any result of statement execution\nother than simple \"success\" or \"failure\" information. This is often the case\nfor \ninsert\n, \nupdate\n and \ndelete\n commands. This use case is covered by\n\nExecutableStatement\n's \nexecute\n method which returns \nFuture\n of \nUnit\n.\n\n\ndef\n \ninsertUser\n(\nname\n:\n \nString\n)\n:\n \nFuture\n[\nUnit\n]\n \n=\n \n{\n\n  \nconn\n.\nstatement\n(\nsql\n\"insert into users(name) values ($name)\"\n).\nexecute\n()\n\n\n}\n\n\n\n\n\n\nExecuting for a single row and for a value\n\u00b6\n\n\nIt is a common use case to expect just a single row to be returned by a query.\nFor instance, when querying by a primary key. This can be easily achieved by\nusing \nExecutableStatement\n's \nexecuteForFirstRow\n method which returns\na \nFuture\n of \nOption[Row]\n. Returned \nOption\n is \nNone\n in case when query\ndoesn't return any results, otherwise, the first row is returned as a \nSome\n.\n\n\nExample:\n\n\ndef\n \nfindUser\n(\nlogin\n:\n \nString\n)\n:\n \nFuture\n[\nOption\n[\nRow\n]]\n \n=\n \n{\n\n  \nconn\n.\nstatement\n(\nsql\n\"select * from users where login = $login\"\n)\n\n      \n.\nexecuteForFirstRow\n()\n\n\n}\n\n\n\n\n\n\nSometimes, not even a single row is needed by a client, only a single column\nvalue, like user's name when searching by login. \nexecuteForValue\n method\ncomes in handy in these kind of situations. The method accepts  a function that\nis supposed to extract this single value from a returned row, if any.\n\n\nSee the example below:\n\n\ndef\n \nfindUsersName\n(\nlogin\n:\n \nString\n)\n:\n \nFuture\n[\nOption\n[\nString\n]]\n \n=\n \n{\n\n  \nconn\n.\nstatement\n(\nsql\n\"select name from users where login = $login\"\n)\n\n      \n.\nexecuteForValue\n(\nr\n \n=>\n \nr\n.\nstr\n(\n\"name\"\n))\n\n\n}\n\n\n\n\n\n\nFor the documentation on how to work with the resulting rows see\n\nResult Rows\n chapter.\n\n\nExecuting for rows affected\n\u00b6\n\n\nWhen executing insert, update or delete statements it may be good to know\nhow many rows were affected by the execution. A number of affected rows can be\nobtained when executing for set or by streaming but if it's the only information\nthat is needed use \nExecutableStatement\n's \nexecuteForRowsAffected\n method\nwhich returns a \nFuture\n of \nLong\n.\n\n\nSee the example below:\n\n\ndef\n \nupdateNames\n(\nname\n:\n \nString\n,\n \nage\n:\n \nInt\n)\n:\n \nFuture\n[\nLong\n]\n \n=\n \n{\n\n  \nconn\n.\nstatement\n(\nsql\n\"update users set name = $name where age = $age\"\n)\n\n      \n.\nexecuteForRowsAffected\n()\n\n\n}\n\n\n\n\n\n\nExecuting for generated key\n\u00b6\n\n\nIf you rely on primary keys being generated by the database when inserting\nnew records you'll need just this one key as a result of the execution. If you\nneed to get multiple generated values then use \nexecuteForStream\n, \nexecuteForSet\n\nor \nexecuteForFirstRow\n described above but for a single one, there is\n\nexecuteForKey\n method. This method executes a statement and returns the first\ncolumn of the first returned row (in most cases the result is going to be a single\nrow with a single column anyway). The method is parametrized by a type of the key.\n\n\nA method in the example below inserts a new user and returns a generated UUID key.\n\n\ndef\n \ninsertUser\n(\nname\n:\n \nString\n,\n \nage\n:\n \nInt\n)\n:\n \nFuture\n[\nUUID\n]\n \n=\n \n{\n\n  \nconn\n.\nstatement\n(\n\n        \nsql\n\"insert into users(name, age) values($name, $age)\"\n,\n\n        \nStatementOptions\n.\nReturnGenKeys\n\n  \n).\nexecuteForKey\n[\nUUID\n]()\n\n\n}\n\n\n\n\n\n\nBatch updates, inserts and deletes\n\u00b6\n\n\nTODO",
            "title": "Statements"
        },
        {
            "location": "/scala/statements/#statement-types",
            "text": "Statements are a core feature of rdbc API. They represent SQL pieces that are sent\nto a database for execution along with arguments, if any. There are two types\nof statements in rdbc: template statements and executable statements. Template\nstatements can't be executed right away. To execute them you first need to bind argument\nfor every parameter they declare. When filled with arguments, template statements\ncreate executable statements. Statements in rdbc are a representation database engine's prepared statements .",
            "title": "Statement types"
        },
        {
            "location": "/scala/statements/#syntax",
            "text": "There isn't much of a syntax to describe. The only thing in a statement syntax\nthat rdbc adds to SQL is how parameters are defined. There are two kinds of\nparameters: named and positional.",
            "title": "Syntax"
        },
        {
            "location": "/scala/statements/#named-parameters",
            "text": "Named parameters:   are alphanumeric identifiers,  can be defined inside a query by prepending parameter identifier with a colon,  can be placed only where database engine expects parameters as defined\n     by a database engine's prepared statement syntax,  are ignored inside varchar literals, column aliases, comments, etc.,  can be referenced by their name or by index (position).   In the following statement just one parameter is declared:  login :  select   *   from   users   where   username   =   : login   A parameter can be used in multiple places. Statement below defines a single\nparameter:  name , but this parameter is used in two places:  select   *   from   users   where   first_name   =   : name   or   middle_name   =   : name    The statement below doesn't declare any parameters. \"fname\" is inside a varchar\nliteral and \"mname\" is part of a comment.  select   *   from   users   where   first_name   =   ':fname'   -- or middle_name = :mname",
            "title": "Named parameters"
        },
        {
            "location": "/scala/statements/#positional-parameters",
            "text": "Positional parameters:   can be defined inside a query by placing a question mark:  ? ,  can be placed only where database engine expects parameters as defined\n     by a database engine's prepared statement syntax,  are ignored inside varchar literals, column aliases, comments, etc.,  can be referenced only by their index (position).   The following example statement uses two positional parameters:  select   *   from   users   where   first_name   =   ?   or   middle_name   =   ?    The statement below doesn't declare any parameters. The first question mark is \ninside a varchar literal and the second is part of a comment.  select   *   from   users   where   first_name   =   '?'   -- or middle_name = ?",
            "title": "Positional parameters"
        },
        {
            "location": "/scala/statements/#creating-statements",
            "text": "",
            "title": "Creating statements"
        },
        {
            "location": "/scala/statements/#bare-strings",
            "text": "Statement can be created using a bare string and then in a separate step be\nfilled with arguments for execution. There is a  statement  method defined in  Connection \ntrait that accepts a string, and returns a  Statement  instance bound to the\nconnection:  val   stmt :   Statement   =   conn . statement ( \n  \"select * from users \"   + \n  \"where (first_name = :name or last_name = :name) and age = :age\"  )   Once you have a  Statement  object, you can bind values to its parameters:    by name  To bind values to parameters by name, use  Statement 's  bind  method that\naccepts a sequence of  (String, Any)  tuples, one for each parameter. Above\nstatement's parameters could be bound to values like this: stmt . bind ( \"name\"   ->   \"Casey\" ,   \"age\"   ->   30 ) .  If you don't provide all parameter values when binding, a  MissingParamValException \nwill be thrown. If you provide value for a parameter that wasn't declared by\nthe query,  NoSuchParamException  will be thrown.  Binding by name is available only if name parameters were used.    by index  There is a possibility to bind values to parameters by index - i.e. just\nprovide a list of values and these values will be matched to every parameter\noccurrence. Arguments can be bound to the above query like this: stmt . bind ( \"Casey\" ,   \"Casey\" ,   30 ) .  If you provide too many parameters  TooManyParamsException  will be thrown.\nIf you provide too few parameters  MissingParamValException  will be thrown.  This method of binding is the only one available if you used positional parameters.    TODO describe what to do with statements without parameters.",
            "title": "Bare strings"
        },
        {
            "location": "/scala/statements/#string-interpolator",
            "text": "Creating statements using simple strings and binding values to parameters in\na separate step is flexible but this flexibility is not really needed in most\ncases. A preferred way of creating statements is by using  sql  string interpolator .  You can get  sql  interpolator into scope either by importing everything from io.rdbc.sapi  package by  import   io.rdbc.sapi._  statement or selectively by import   io.rdbc.sapi.SqlInterpolator._  statement.  Once you have it in scope, you can use it to declare parameters and bind values\nto them in one step, like this:  val   conn :   Connection   =   ???  def   findUsersStmt ( name :   String ) :   ExecutableStatement   =   { \n    conn . statement ( sql \"select * from users where name = $name\" )  }   As you can see, when  sql  interpolator is used  Connection 's  statement  method\nproduces  ExecutableStatement , so the statement already has values\nbound to its parameters. The above example is equivalent to the following, somewhat\nless concise snippet:  def   findUsersStmt ( name :   String ) :   ExecutableStatement   =   {    \n     conn . statement ( \"select * from users where name = ?\" ) \n         . bindByIdx ( name )  }   SQL parts created by  sql  interpolator can be concatenated in the same way you\nwould concatenate plain strings:  def   findUsersStmt ( name :   String ,   age :   Int ) :   ExecutableStatement   =   { \n   conn . statement ( \n    sql \"select * from users \"   + \n    sql \"where (first_name = $name or last_name = $name) and age = $age\" \n   )  }   Important thing to understand is that when using  sql  interpolator you're still\nsafe from creating SQL injection vulnerability. Parameter values are  not  passed\nin to the database as literals concatenated with the rest of the SQL.",
            "title": "String interpolator"
        },
        {
            "location": "/scala/statements/#dynamic-sql",
            "text": "Sometimes, most notably in tests or some one-time use scripts, it may be useful\nto create SQL dynamically, like this:  def   stmt ( table :   String ,   name :   String ) :   FutureExecutableStatement   =   { \n   conn . statement ( s\"select * from  $table  where name = :name\" ) \n       . bind ( \"name\"   ->   name )  }   If you want to create SQL dynamically and still benefit from  sql  interpolator\nfeatures, use  #$  prefix for dynamic parts, like this:  def   sql ( table :   String ,   name :   String ) :   ExecutableStatement   =   { \n   conn . statement ( sql \"select * from #$table where name = $name\" )  }   In the above example, only  $name  is a statement parameter,  #$table  will be\nsimply replaced by  table  method parameter value.",
            "title": "Dynamic SQL"
        },
        {
            "location": "/scala/statements/#options",
            "text": "When creating a statement you can provide options that can tweak statement's\nbehavior. To pass options, use  Connection 's  statement  methods that accept\nsecond argument of  StatementOptions  type.  The list below contains currently supported options:     Option:   generatedKeyCols  Controls statement behavior regarding returning keys generated by the\n database when issuing update or insert statements.  Possible values :   KeyColumns.All  \u2014 all columns with generated keys will be returned  KeyColumns.None  \u2014 no columns with generated keys will be returned  KeyColumns.named(cols: String*)  \u2014 only columns listed by name will be returned   Default value :  KeyColumns.None     StatementOptions  is a case class and in its companion object there is  Default \ninstance of it with the default option values. You can use this instance to\ntweak only some of the options using built-in  copy  method:  conn . statement ( \n   sql \"insert into users(name) values ($name)\" , \n   Default . copy ( option1   =   value1 ,   option2   =   value2 )  )",
            "title": "Options"
        },
        {
            "location": "/scala/statements/#executing-statements",
            "text": "Once you have an  ExecutableStatement  instance, you can execute it in a couple\nof different ways. The method of execution controls in what shape you get the\nresults from the database. Paragraphs below describe methods of executing statements.",
            "title": "Executing statements"
        },
        {
            "location": "/scala/statements/#executing-for-a-result-set",
            "text": "Arguably the simplest method of execution that returns results is to execute\nstatement for a result set. To do this, use  ExecutableStatement 's executeForSet  method that returns  Future  of  ResultSet .  ResultSet  gives you access to the rows as well as to the metadata like warnings\nissued by the DB engine, columns metadata and count of rows affected by the statement.\nIt also implements  Traversable  trait providing a convenience method of traversing\nthrough the rows.  Executing for set is simple, but be aware that for bigger sets you may encounter OutOfMemoryError s. All results are stored in memory, there is no paging of any\nkind. If you want to avoid this sort of problems, consider streaming  the results.  For the documentation on how to work with the resulting rows see Result Rows  chapter.  TODO example",
            "title": "Executing for a result set"
        },
        {
            "location": "/scala/statements/#streaming-results",
            "text": "To stream results from the database, use  ExecutableStatement 's  stream \nmethod. This method returns  RowPublisher  instance which implements\nreactive stream's  Publisher  interface. Items published are rows represented\nby  Row  trait. For the documentation on how to work with the resulting rows see Result Rows  chapter.  Here are a couple of things to know when working with streams:   statement execution is deferred until publisher is subscribed to,  a publisher can be subscribed to only once,  after  stream  method is invoked, connection is considered busy and can be used\n     for other queries only after the stream completes or is cancelled,  cancel is an asynchronous operation and reactive streams specification doesn't\n     provide a way of notifying a client that cancel operation completed. If clients\n     want to use the connection after stream cancellation, they must watch for\n     connection's  watchForIdle   Future  completion before requesting any\n     subsequent operations.   Processing streams is out of scope of this manual, for details please refer to\ndocumentation of libraries that are built to facilitate this, like Akka stream  or  Monix .  TODO describe how to release connection after stream completion  TODO example",
            "title": "Streaming results"
        },
        {
            "location": "/scala/statements/#executing-ignoring-results",
            "text": "In many cases clients are not interested in any result of statement execution\nother than simple \"success\" or \"failure\" information. This is often the case\nfor  insert ,  update  and  delete  commands. This use case is covered by ExecutableStatement 's  execute  method which returns  Future  of  Unit .  def   insertUser ( name :   String ) :   Future [ Unit ]   =   { \n   conn . statement ( sql \"insert into users(name) values ($name)\" ). execute ()  }",
            "title": "Executing ignoring results"
        },
        {
            "location": "/scala/statements/#executing-for-a-single-row-and-for-a-value",
            "text": "It is a common use case to expect just a single row to be returned by a query.\nFor instance, when querying by a primary key. This can be easily achieved by\nusing  ExecutableStatement 's  executeForFirstRow  method which returns\na  Future  of  Option[Row] . Returned  Option  is  None  in case when query\ndoesn't return any results, otherwise, the first row is returned as a  Some .  Example:  def   findUser ( login :   String ) :   Future [ Option [ Row ]]   =   { \n   conn . statement ( sql \"select * from users where login = $login\" ) \n       . executeForFirstRow ()  }   Sometimes, not even a single row is needed by a client, only a single column\nvalue, like user's name when searching by login.  executeForValue  method\ncomes in handy in these kind of situations. The method accepts  a function that\nis supposed to extract this single value from a returned row, if any.  See the example below:  def   findUsersName ( login :   String ) :   Future [ Option [ String ]]   =   { \n   conn . statement ( sql \"select name from users where login = $login\" ) \n       . executeForValue ( r   =>   r . str ( \"name\" ))  }   For the documentation on how to work with the resulting rows see Result Rows  chapter.",
            "title": "Executing for a single row and for a value"
        },
        {
            "location": "/scala/statements/#executing-for-rows-affected",
            "text": "When executing insert, update or delete statements it may be good to know\nhow many rows were affected by the execution. A number of affected rows can be\nobtained when executing for set or by streaming but if it's the only information\nthat is needed use  ExecutableStatement 's  executeForRowsAffected  method\nwhich returns a  Future  of  Long .  See the example below:  def   updateNames ( name :   String ,   age :   Int ) :   Future [ Long ]   =   { \n   conn . statement ( sql \"update users set name = $name where age = $age\" ) \n       . executeForRowsAffected ()  }",
            "title": "Executing for rows affected"
        },
        {
            "location": "/scala/statements/#executing-for-generated-key",
            "text": "If you rely on primary keys being generated by the database when inserting\nnew records you'll need just this one key as a result of the execution. If you\nneed to get multiple generated values then use  executeForStream ,  executeForSet \nor  executeForFirstRow  described above but for a single one, there is executeForKey  method. This method executes a statement and returns the first\ncolumn of the first returned row (in most cases the result is going to be a single\nrow with a single column anyway). The method is parametrized by a type of the key.  A method in the example below inserts a new user and returns a generated UUID key.  def   insertUser ( name :   String ,   age :   Int ) :   Future [ UUID ]   =   { \n   conn . statement ( \n         sql \"insert into users(name, age) values($name, $age)\" , \n         StatementOptions . ReturnGenKeys \n   ). executeForKey [ UUID ]()  }",
            "title": "Executing for generated key"
        },
        {
            "location": "/scala/statements/#batch-updates-inserts-and-deletes",
            "text": "TODO",
            "title": "Batch updates, inserts and deletes"
        },
        {
            "location": "/scala/types/",
            "text": "Warning\n\n\nrdbc project and this documentation is still a work in progress.\nIt's not ready yet for production use.\n\n\n\n\nBoth when passing arguments to statements and when processing resulting rows\nthere is a need to convert values between database data types and Scala types.\nParagraphs below describe the mapping and possible conversions.\n\n\nType mapping\n\u00b6\n\n\nFollowing table lists mapping between Scala and SQL types.\n\n\n\n\n\n\n\n\nSQL type\n\n\nScala type\n\n\n\n\n\n\n\n\n\n\nCHAR\n\n\nString\n\n\n\n\n\n\nVARCHAR\n\n\nString\n\n\n\n\n\n\nNCHAR\n\n\nString\n\n\n\n\n\n\nNVARCHAR\n\n\nString\n\n\n\n\n\n\nCLOB\n\n\nString\n\n\n\n\n\n\nNCLOB\n\n\nString\n\n\n\n\n\n\nBINARY\n\n\nArray[Byte]\n\n\n\n\n\n\nVARBINARY\n\n\nArray[Byte]\n\n\n\n\n\n\nBLOB\n\n\nArray[Byte]\n\n\n\n\n\n\nBOOLEAN\n\n\nBoolean\n\n\n\n\n\n\nNUMERIC\n\n\nio.rdbc.sapi.SqlNumeric\n\n\n\n\n\n\nDECIMAL\n\n\nio.rdbc.sapi.SqlNumeric\n\n\n\n\n\n\nREAL\n\n\nFloat\n\n\n\n\n\n\nDOUBLE\n\n\nDouble\n\n\n\n\n\n\nSMALLINT\n\n\nShort\n\n\n\n\n\n\nINTEGER\n\n\nInt\n\n\n\n\n\n\nBIGINT\n\n\nLong\n\n\n\n\n\n\nDATE\n\n\njava.time.LocalDate\n\n\n\n\n\n\nTIME\n\n\njava.time.LocalTime\n\n\n\n\n\n\nTIMESTAMP\n\n\njava.time.LocalDateTime\n\n\n\n\n\n\nTIMESTAMP WITH TIME ZONE\n\n\njava.time.Instant\n\n\n\n\n\n\n\n\nFollowing table lists mapping between Scala and database types not defined\nby the SQL standard.\n\n\n\n\n\n\n\n\nSQL type\n\n\nScala type\n\n\n\n\n\n\n\n\n\n\nUUID\n\n\njava.util.UUID\n\n\n\n\n\n\n\n\nResult type conversions\n\u00b6\n\n\nSQL types listed in \nType mapping\n paragraph can be represented \nnot only by their direct Scala counterparts. For example, NUMERIC can also be\nconverted to Scala's \nFloat\n. If user requests NUMERIC column value as a \nFloat\n,\n\nFloat\n will be returned, possibly losing precision. The table below lists possible\nconversions.\n\n\n\n\n\n\n\n\nSource SQL type\n\n\nTarget Scala type\n\n\nNotes\n\n\n\n\n\n\n\n\n\n\nCHAR, NCHAR\n\n\nBoolean\n\n\n'1'\n, \n'T'\n, \n'Y'\n converts to \ntrue\n.\n'0'\n, \n'F'\n, \n'N'\n converts to \nfalse\n.\n\n\n\n\n\n\nDECIMAL, NUMERIC, REAL, DOUBLE, INTEGER, SMALLINT, BIGINT\n\n\nBoolean\n\n\n1 converts to \ntrue\n.\n0 converts to \nfalse\n.\n\n\n\n\n\n\nVARCHAR, NVARCHAR,\nCLOB, NCLOB\n\n\nBigDecimal\n, \nSqlNumeric\n\n\nTextual value is converted by rules defined \nhere\n.\n\n\n\n\n\n\nVARCHAR, NVARCHAR,\nCLOB, NCLOB\n\n\njava.util.UUID\n\n\nTextual value is converted by rules defined \nhere\n.\n\n\n\n\n\n\nDECIMAL, NUMERIC, REAL, DOUBLE, INTEGER, SMALLINT, BIGINT\n\n\nFloat\n, \nDouble\n, \nByte\n, \nShort\n, \nInt\n, \nLong\n\n\nValue may be rounded and/or truncated.\n\n\n\n\n\n\nINTEGER, SMALLINT, BIGINT\n\n\nBigDecimal\n\n\n\n\n\n\n\n\nDECIMAL, NUMERIC, REAL, DOUBLE\n\n\nBigDecimal\n\n\nInfinity and NaN are not convertible.\n\n\n\n\n\n\nVARCHAR, NVARCHAR,\nCLOB, NCLOB\n\n\nCHAR\n\n\nValues containing single character are convertible.\n\n\n\n\n\n\nTIMESTAMP\n\n\njava.time.LocalDate\n\n\nTime part is truncated.\n\n\n\n\n\n\nTIMESTAMP\n\n\njava.time.LocalTime\n\n\nDate part is truncated.\n\n\n\n\n\n\n\n\nIf client requests to convert between inconvertible types, \nConversionException\n\nis thrown.\n\n\nStatement argument type conversions\n\u00b6\n\n\nWhen setting statement arguments, in case when a given Scala type maps to more\nthan one database type there is no way for the API client to enforce conversion\nto a specific database type. This is the case only for two Scala types: \nString\n\nwhich always maps to NVARCHAR and \nArray[Byte]\n which always maps to VARBINARY.\n\n\nVendor specific types\n\u00b6\n\n\nrdbc driver implementing support for a particular database vendor may provide\nadditional type mappings and conversions. Consult the driver's documentation\non this topic.",
            "title": "Data types"
        },
        {
            "location": "/scala/types/#type-mapping",
            "text": "Following table lists mapping between Scala and SQL types.     SQL type  Scala type      CHAR  String    VARCHAR  String    NCHAR  String    NVARCHAR  String    CLOB  String    NCLOB  String    BINARY  Array[Byte]    VARBINARY  Array[Byte]    BLOB  Array[Byte]    BOOLEAN  Boolean    NUMERIC  io.rdbc.sapi.SqlNumeric    DECIMAL  io.rdbc.sapi.SqlNumeric    REAL  Float    DOUBLE  Double    SMALLINT  Short    INTEGER  Int    BIGINT  Long    DATE  java.time.LocalDate    TIME  java.time.LocalTime    TIMESTAMP  java.time.LocalDateTime    TIMESTAMP WITH TIME ZONE  java.time.Instant     Following table lists mapping between Scala and database types not defined\nby the SQL standard.     SQL type  Scala type      UUID  java.util.UUID",
            "title": "Type mapping"
        },
        {
            "location": "/scala/types/#result-type-conversions",
            "text": "SQL types listed in  Type mapping  paragraph can be represented \nnot only by their direct Scala counterparts. For example, NUMERIC can also be\nconverted to Scala's  Float . If user requests NUMERIC column value as a  Float , Float  will be returned, possibly losing precision. The table below lists possible\nconversions.     Source SQL type  Target Scala type  Notes      CHAR, NCHAR  Boolean  '1' ,  'T' ,  'Y'  converts to  true . '0' ,  'F' ,  'N'  converts to  false .    DECIMAL, NUMERIC, REAL, DOUBLE, INTEGER, SMALLINT, BIGINT  Boolean  1 converts to  true . 0 converts to  false .    VARCHAR, NVARCHAR, CLOB, NCLOB  BigDecimal ,  SqlNumeric  Textual value is converted by rules defined  here .    VARCHAR, NVARCHAR, CLOB, NCLOB  java.util.UUID  Textual value is converted by rules defined  here .    DECIMAL, NUMERIC, REAL, DOUBLE, INTEGER, SMALLINT, BIGINT  Float ,  Double ,  Byte ,  Short ,  Int ,  Long  Value may be rounded and/or truncated.    INTEGER, SMALLINT, BIGINT  BigDecimal     DECIMAL, NUMERIC, REAL, DOUBLE  BigDecimal  Infinity and NaN are not convertible.    VARCHAR, NVARCHAR, CLOB, NCLOB  CHAR  Values containing single character are convertible.    TIMESTAMP  java.time.LocalDate  Time part is truncated.    TIMESTAMP  java.time.LocalTime  Date part is truncated.     If client requests to convert between inconvertible types,  ConversionException \nis thrown.",
            "title": "Result type conversions"
        },
        {
            "location": "/scala/types/#statement-argument-type-conversions",
            "text": "When setting statement arguments, in case when a given Scala type maps to more\nthan one database type there is no way for the API client to enforce conversion\nto a specific database type. This is the case only for two Scala types:  String \nwhich always maps to NVARCHAR and  Array[Byte]  which always maps to VARBINARY.",
            "title": "Statement argument type conversions"
        },
        {
            "location": "/scala/types/#vendor-specific-types",
            "text": "rdbc driver implementing support for a particular database vendor may provide\nadditional type mappings and conversions. Consult the driver's documentation\non this topic.",
            "title": "Vendor specific types"
        },
        {
            "location": "/scala/rows/",
            "text": "Warning\n\n\nrdbc project and this documentation is still a work in progress.\nIt's not ready yet for production use.\n\n\n\n\nStatement rows are represented in rdbc as \nRow\n trait. This chapter describes\nthis trait and methods it provides that give access column values.\n\n\nGeneric methods\n\u00b6\n\n\nRow\n trait declares a family of \ncol\n methods that allow accessing column\nvalues of any Scala type. The methods accept a single type parameter telling\nrdbc what Scala type should be used to represent a database value \u2014 see\nthe list below for their simplified declarations.\n\n\n\n\ndef\n \ncol\n[\nA\n](\nidx\n:\n \nInt\n)\n:\n \nA\n\n\ndef\n \ncolOpt\n[\nA\n](\nidx\n:\n \nInt\n)\n:\n \nOption\n[\nA\n]\n\n\ndef\n \ncol\n[\nA\n](\nname\n:\n \nString\n)\n:\n \nA\n\n\ndef\n \ncolOpt\n[\nA\n](\nname\n:\n \nString\n)\n:\n \nOption\n[\nA\n]\n\n\n\n\nThe methods differ from one another in two areas:\n\n\n\n\n\n\nNamed vs unnamed columns\n\n\nTo fetch column value by name use method that accepts a \nString\n;\n to fetch value by column's index, use the version that accepts an \nInt\n.\n\n\n\n\n\n\nNull-safety\n\n\ncolOpt\n methods are null-safe, and \ncol\n methods aren't. You can't use\n plain \ncol\n method to get SQL \nNULL\n values. If you try that, \nConversionException\n\n will be thrown. \ncolOpt\n returns \nOption\n so it's fit for handling \nNULL\ns\n \u2014 it represents them by \nNone\n. \ncol\n method is intended to be used\n only for columns that can't hold \nNULL\n values, for example because there is\n a not-null constraint defined for them.\n\n\n\n\n\n\nType-specific methods\n\u00b6\n\n\nRow\n trait, for convenience, also provides methods that aren't parametrized\nby type and their names reflect the type they return. They are simply shortcuts\nfor calling generic \ncol\n methods described earlier. For instance, there is a\n\nstr\n method that is a shortcut for calling \ncol[String]\n method. See the \n\nRow\n Scaladoc\n for a complete list.\n\n\nIf you want to use types supported by the particular driver but not supported\nby default by rdbc, you must always use generic \ncol\n methods.",
            "title": "Result Rows"
        },
        {
            "location": "/scala/rows/#generic-methods",
            "text": "Row  trait declares a family of  col  methods that allow accessing column\nvalues of any Scala type. The methods accept a single type parameter telling\nrdbc what Scala type should be used to represent a database value \u2014 see\nthe list below for their simplified declarations.   def   col [ A ]( idx :   Int ) :   A  def   colOpt [ A ]( idx :   Int ) :   Option [ A ]  def   col [ A ]( name :   String ) :   A  def   colOpt [ A ]( name :   String ) :   Option [ A ]   The methods differ from one another in two areas:    Named vs unnamed columns  To fetch column value by name use method that accepts a  String ;\n to fetch value by column's index, use the version that accepts an  Int .    Null-safety  colOpt  methods are null-safe, and  col  methods aren't. You can't use\n plain  col  method to get SQL  NULL  values. If you try that,  ConversionException \n will be thrown.  colOpt  returns  Option  so it's fit for handling  NULL s\n \u2014 it represents them by  None .  col  method is intended to be used\n only for columns that can't hold  NULL  values, for example because there is\n a not-null constraint defined for them.",
            "title": "Generic methods"
        },
        {
            "location": "/scala/rows/#type-specific-methods",
            "text": "Row  trait, for convenience, also provides methods that aren't parametrized\nby type and their names reflect the type they return. They are simply shortcuts\nfor calling generic  col  methods described earlier. For instance, there is a str  method that is a shortcut for calling  col[String]  method. See the  Row  Scaladoc  for a complete list.  If you want to use types supported by the particular driver but not supported\nby default by rdbc, you must always use generic  col  methods.",
            "title": "Type-specific methods"
        },
        {
            "location": "/scala/exceptions/",
            "text": "Warning\n\n\nrdbc project and this documentation is still a work in progress.\nIt's not ready yet for production use.\n\n\n\n\nTODO",
            "title": "Exceptions"
        },
        {
            "location": "/scala/frameworks/",
            "text": "Warning\n\n\nrdbc project and this documentation is still a work in progress.\nIt's not ready yet for production use.\n\n\n\n\nTODO",
            "title": "Frameworks integration"
        },
        {
            "location": "/scala/utilities/",
            "text": "Warning\n\n\nrdbc project and this documentation is still a work in progress.\nIt's not ready yet for production use.\n\n\n\n\nTODO",
            "title": "Utilities"
        },
        {
            "location": "/scala/faq/",
            "text": "Warning\n\n\nrdbc project and this documentation is still a work in progress.\nIt's not ready yet for production use.\n\n\n\n\nHere are some questions that have a potential to become frequently asked.\n\n\n\n\n\n\nI have plenty of time, I don't want to use any timeout for any of my queries. What can I do?\n\n\nImport \nTimeout\n instance of infinite duration either by importing \nio.rdbc.sapi._\n\n  or directly \nio.rdbc.sapi.Timeout.Implicits.inf\n.\n\n\n\n\n\n\n\n\nHow do I build SQL dynamically using \nsql\n interpolator?\n\n\nUse special \n#$\n prefix for the dynamic parts. See \nthis\n\n  paragraph for details.\n\n\n\n\n\n\n\n\nHow to pass \nTimeout\n explicitly to \nExecutableStatement\n's \nexecuteForKey\n method? I keep getting compilation errors.\n\n\nexecuteForKey\n method's declaration is\n\n\ndef\n \nexecuteForKey\n[\nK:\n \nClassTag\n]()(\nimplicit\n \ntimeout\n:\n \nTimeout\n)\n:\n \nFuture\n[\nK\n]\n\n\n\n\n\n\nUnder the hood, this declaration really means this:\n\n\ndef\n \nexecuteForKey\n[\nK\n]()(\nimplicit\n \nclassTag\n:\n \nClassTag\n[\nK\n],\n \ntimeout\n:\n \nTimeout\n)\n:\n \nFuture\n[\nK\n]\n\n\n\n\n\n\nSo you can't really execute this method like this: \n\n\nexecuteForKey\n[\nInt\n]()(\ntimeout\n)\n\n\n\n\n\n\nInstead, you have to do this:\n\n\nexecuteForKey\n()(\ntimeout\n,\n \nclassOf\n[\nInt\n])\n\n\n\n\n\n\n\n\n\n\n\n\nI'm executing insert statement and trying to get auto-generated key from the DB but nothing is returned. What am I doing wrong?\n\n\nYou probably forgot to set a \ngeneratedKeyCols\n statement option accordingly.\n  See \nthis\n paragraph for details.",
            "title": "FAQ"
        },
        {
            "location": "/java/java/",
            "text": "Warning\n\n\nrdbc project and this documentation is still a work in progress.\nIt's not ready yet for production use.\n\n\n\n\nJava API is not yet available. Work is being performed in\n\njava\n git branch.",
            "title": "Java API user guide"
        },
        {
            "location": "/drivers/",
            "text": "Warning\n\n\nrdbc project and this documentation is still a work in progress.\nIt's not ready yet for production use.\n\n\n\n\nEven though this documentation is database vendor-agnostic, for reader's\nconvenience the list below contains information about available rdbc driver\nimplementations categorized by a database vendor.\n\n\nYes, the documentation author is aware that the list currently contains only one item.\n\n\nPostgreSQL\n\u00b6\n\n\n\n\n\n\nrdbc-pgsql\n\n\nNetty-based PostgreSQL rdbc driver.\n\n\nWebsite: \nhttps://github.com/rdbc-io/rdbc-pgsql",
            "title": "Drivers"
        },
        {
            "location": "/drivers/#postgresql",
            "text": "rdbc-pgsql  Netty-based PostgreSQL rdbc driver.  Website:  https://github.com/rdbc-io/rdbc-pgsql",
            "title": "PostgreSQL"
        },
        {
            "location": "/examples/",
            "text": "Warning\n\n\nrdbc project and this documentation is still a work in progress.\nIt's not ready yet for production use.\n\n\n\n\nExample projects are implemented in\n\nrdbc-io/rdbc-examples\n\nGitHub repository. For detailed description of these samples see the repository's\nREADME.",
            "title": "Examples"
        }
    ]
}