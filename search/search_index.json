{
    "docs": [
        {
            "location": "/",
            "text": "What is rdbc?\n\u00b6\n\n\nrdbc is a SQL-level relational database connectivity API targeting Scala and \nJava programming languages. The API is fully asynchronous and provides\na possibility to leverage \nReactive Streams'\n\nstream processing capabilities.\n\n\nGoals\n\u00b6\n\n\nFollowing list outlines the goals of the API:\n\n\n\n\n\n\nProvide vendor neutral access to most commonly used database features.\n\n\nThe API is meant to be vendor neutral in a sense that if clients stick\nto using only standard SQL features no vendor-specific code should be needed\nand database backends can be switched with no client code changes.\n\n\n\n\n\n\nBe asynchronous and reactive.\n\n\nAll methods that can potentially perform I/O actions don't block the executing\nthread so the API fits well into a non-blocking application design. rdbc\nallows building applications according to the \nReactive Manifesto\n\nby using \nReactive Streams\n for asynchronous\nresults streaming with a back-pressure.\n\n\n\n\n\n\nProvide a foundation for higher-level APIs.\n\n\nrdbc is a rather low-level API enabling clients to use plain SQL queries\nand get results back. While it can be used directly it's also meant to \nprovide a foundation for higher-level APIs like functional or object\nrelational mapping libraries.\n\n\n\n\n\n\nNon-goals\n\u00b6\n\n\nFollowing list outlines the areas that the API is not meant to cover.\n\n\n\n\n\n\nProvide a full type-safety.\n\n\nrdbc works on a SQL level, meaning that requests made to the database\nare strings. There is no additional layer that would ensure type-safety\nwhen working with SQL. The API is also meant to be dynamic and allow type\nconverters to be registered at runtime. This approach sacrifices some\ntype-safety but at the same time makes it possible to implement wider range\nof higher-level APIs on top of rdbc.\n\n\n\n\n\n\nProject status\n\u00b6\n\n\nBoth Scala and Java APIs are now complete. More feedback from the community is\nneeded before releasing the first 1.0.0 milestone.\n\n\nGetting help\n\u00b6\n\n\nJoin \nrdbc-io/rdbc\n gitter channel for \nquestions and any kind of discussion about rdbc. You are also free to\nask your question by creating a Github \nissue\n.\n\n\nSee also \nrdbc\n\ntag on StackOverflow.\n\n\nLicense\n\u00b6\n\n\nrdbc is an open source software licensed under\n\nApache License 2.0\n.",
            "title": "Introduction"
        },
        {
            "location": "/#what-is-rdbc",
            "text": "rdbc is a SQL-level relational database connectivity API targeting Scala and \nJava programming languages. The API is fully asynchronous and provides\na possibility to leverage  Reactive Streams' \nstream processing capabilities.",
            "title": "What is rdbc?"
        },
        {
            "location": "/#goals",
            "text": "Following list outlines the goals of the API:    Provide vendor neutral access to most commonly used database features.  The API is meant to be vendor neutral in a sense that if clients stick\nto using only standard SQL features no vendor-specific code should be needed\nand database backends can be switched with no client code changes.    Be asynchronous and reactive.  All methods that can potentially perform I/O actions don't block the executing\nthread so the API fits well into a non-blocking application design. rdbc\nallows building applications according to the  Reactive Manifesto \nby using  Reactive Streams  for asynchronous\nresults streaming with a back-pressure.    Provide a foundation for higher-level APIs.  rdbc is a rather low-level API enabling clients to use plain SQL queries\nand get results back. While it can be used directly it's also meant to \nprovide a foundation for higher-level APIs like functional or object\nrelational mapping libraries.",
            "title": "Goals"
        },
        {
            "location": "/#non-goals",
            "text": "Following list outlines the areas that the API is not meant to cover.    Provide a full type-safety.  rdbc works on a SQL level, meaning that requests made to the database\nare strings. There is no additional layer that would ensure type-safety\nwhen working with SQL. The API is also meant to be dynamic and allow type\nconverters to be registered at runtime. This approach sacrifices some\ntype-safety but at the same time makes it possible to implement wider range\nof higher-level APIs on top of rdbc.",
            "title": "Non-goals"
        },
        {
            "location": "/#project-status",
            "text": "Both Scala and Java APIs are now complete. More feedback from the community is\nneeded before releasing the first 1.0.0 milestone.",
            "title": "Project status"
        },
        {
            "location": "/#getting-help",
            "text": "Join  rdbc-io/rdbc  gitter channel for \nquestions and any kind of discussion about rdbc. You are also free to\nask your question by creating a Github  issue .  See also  rdbc \ntag on StackOverflow.",
            "title": "Getting help"
        },
        {
            "location": "/#license",
            "text": "rdbc is an open source software licensed under Apache License 2.0 .",
            "title": "License"
        },
        {
            "location": "/scala/gettingstarted/",
            "text": "Adding rdbc to your project\n\u00b6\n\n\nrdbc is just an API \u2014 to actually use it as a database client you need\nan implementation called a driver. So \u2014 to use rdbc in your project you need\nto include \ntwo\n dependencies, one for the API, and one for a driver. This \ndocumentation doesn't describe any particular driver \u2014 you should be able to\nfind artifact names you need to include in your build definition in the driver's\ndocumentation. For your convenience, however, \nDrivers\n page lists available\ndrivers grouped by a database engine they support.\n\n\nrdbc JARs are published to\n\nMaven Central\n\nrepository. The API is currently available for Scala 2.11 and 2.12 and requires\nJava 8 runtime or newer.\n\n\nSBT\n\u00b6\n\n\nFor sbt projects, add the following to \nbuild.sbt\n:\n\n\nlibraryDependencies\n \n++=\n \nVector\n(\n\n  \n\"io.rdbc\"\n \n%%\n \n\"rdbc-api-scala\"\n \n%\n \n\"{{version}}\"\n,\n\n  \n//here goes the driver dependency\n\n\n)\n\n\n\n\n\n\nGradle\n\u00b6\n\n\nFor Gradle projects, add the following to the \ndependencies\n section of \nbuild.gradle\n:\n\n\nScala 2.12\n\n\ncompile\n \ngroup:\n \n'io.rdbc'\n,\n \nname:\n \n'rdbc-api-scala_2.12'\n,\n \nversion:\n \n'{{version}}'\n\n\ncompile\n \n//here goes the driver dependency\n\n\n\n\n\n\nScala 2.11\n\n\ncompile\n \ngroup:\n \n'io.rdbc'\n,\n \nname:\n \n'rdbc-api-scala_2.11'\n,\n \nversion:\n \n'{{version}}'\n\n\ncompile\n \n//here goes the driver dependency\n\n\n\n\n\n\nMaven\n\u00b6\n\n\nFor Maven projects, add the following to the \ndependencies\n element of \npom.xml\n:\n\n\nScala 2.12\n\n\n<dependency>\n\n  \n<groupId>\nio.rdbc\n</groupId>\n\n  \n<artifactId>\nrdbc-api-scala_2.12\n</artifactId>\n\n  \n<version>\n{{version}}\n</version>\n\n\n</dependency>\n\n\n<dependency>\n\n  \n<!-- here goes the driver dependency -->\n\n\n</dependency>\n\n\n\n\n\n\nScala 2.11\n\n\n<dependency>\n\n  \n<groupId>\nio.rdbc\n</groupId>\n\n  \n<artifactId>\nrdbc-api-scala_2.11\n</artifactId>\n\n  \n<version>\n{{version}}\n</version>\n\n\n</dependency>\n\n\n<dependency>\n\n  \n<!-- here goes the driver dependency -->\n\n\n</dependency>\n\n\n\n\n\n\nWorking with Scala \nFuture\ns\n\u00b6\n\n\nSince all rdbc API methods that perform I/O return Scala's \nFuture\ns you'll\nneed a knowledge on how to write asynchronous code using them. Throughout this \ndocumentation it is assumed that the reader has a basic knowledge about \nFuture\n\ntrait. If you're new to this concept you may find these resources useful:\n\n\n\n\nThe Neophyte's Guide to Scala\n\n\nOfficial documentation\n\n\n\n\nA \"Hello world\" application\n\u00b6\n\n\nIt's time for a small but complete example of rdbc API usage. A snippet below\ninserts a \"Hello world!\" greeting into a \nmessages\n database table. \n\n\nA table with the following definition is assumed to exist:\n\n\ncreate\n \ntable\n \nmessages\n(\ntxt\n \nvarchar\n(\n100\n))\n\n\n\n\n\n\nAnd here's the actual code snippet:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\nimport\n \nio.rdbc.sapi._\n\n\n\nimport\n \nscala.concurrent.ExecutionContext.Implicits.global\n\n\nimport\n \nscala.concurrent.duration._\n\n\nimport\n \nscala.concurrent.\n{\nAwait\n,\n \nFuture\n}\n\n\nimport\n \nscala.util.\n{\nFailure\n,\n \nSuccess\n}\n\n\n\nobject\n \nHelloRdbc\n \nextends\n \nApp\n \n{\n\n\n  \nval\n \nconnFactory\n:\n \nConnectionFactory\n \n=\n \n???\n\n\n  \nval\n \ngreeting\n \n=\n \n\"Hello World!\"\n\n  \nval\n \ninsertFut\n:\n \nFuture\n[\nLong\n]\n \n=\n \nconnFactory\n.\nwithConnection\n \n{\n \nconn\n \n=>\n\n    \nconn\n\n      \n.\nstatement\n(\nsql\n\"insert into messages(txt) values ($greeting)\"\n)\n\n      \n.\nexecuteForRowsAffected\n()\n\n  \n}.\nandThen\n \n{\n\n    \ncase\n \nSuccess\n(\ncount\n)\n \n=>\n \nprintln\n(\ns\"inserted \n$count\n greeting(s)\"\n)\n\n    \ncase\n \nFailure\n(\nex\n)\n \n=>\n \nex\n.\nprintStackTrace\n()\n\n  \n}\n\n\n  \nAwait\n.\nready\n(\n\n    \ninsertFut\n.\ntransformWith\n(\n_\n \n=>\n \nconnFactory\n.\nshutdown\n()),\n\n    \n10.\nseconds\n\n  \n)\n\n\n}\n\n\n\n\n\n\n\nIn this very simple application:\n\n\n\n\n\n\nAt line \n10\n a\n   \nConnectionFactory\n\n   coming from a driver package should be instantiated. Each rdbc driver provides\n   an implementation of this trait that allows to estabilish a connection to a database.\n   \nConnectionFactory\n implementation and classes needed for its configuration should\n   be the only classes directly used from the driver package.\n\n\n\n\n\n\nAt line \n13\n a connection to the database is requested to be estabilished - \n   when that happens, a function passed as a code block is executed.\n\n\n\n\n\n\nIn this code block, at line \n15\n a prepared statement is requested to be\n   created using a\n   \nsql\n\n   \nstring interpolator\n\n   which passes a \ngreeting\n string argument to it.\n\n\n\n\n\n\nThe statement is requested to be executed at line \n16\n and\n   to return number of affected rows.\n\n\n\n\n\n\nWhen the database operation finishes and the connection is released, at line\n   \n17\n the \nFuture\n's result is handled: number of affected rows is printed in\n   case of a success or a stack trace is printed in case of an error.\n\n\n\n\n\n\nNone of the database calls block the executing thread - all of them return\n   \nFuture\ns that are then chained. The only statement that blocks starts at line\n   \n22\n when the application waits for operations requested earlier to complete.\n   Because this demo is just a simple console application, we need to block the\n   thread somewhere to wait for a moment that the application can exit.\n\n\n\n\n\n\nScaladoc\n\u00b6\n\n\nYou can browse Scaladoc using javadoc.io site \n\nhere\n. The site\nallows to switch between Scala versions and rdbc versions.",
            "title": "Getting started"
        },
        {
            "location": "/scala/gettingstarted/#adding-rdbc-to-your-project",
            "text": "rdbc is just an API \u2014 to actually use it as a database client you need\nan implementation called a driver. So \u2014 to use rdbc in your project you need\nto include  two  dependencies, one for the API, and one for a driver. This \ndocumentation doesn't describe any particular driver \u2014 you should be able to\nfind artifact names you need to include in your build definition in the driver's\ndocumentation. For your convenience, however,  Drivers  page lists available\ndrivers grouped by a database engine they support.  rdbc JARs are published to Maven Central \nrepository. The API is currently available for Scala 2.11 and 2.12 and requires\nJava 8 runtime or newer.",
            "title": "Adding rdbc to your project"
        },
        {
            "location": "/scala/gettingstarted/#sbt",
            "text": "For sbt projects, add the following to  build.sbt :  libraryDependencies   ++=   Vector ( \n   \"io.rdbc\"   %%   \"rdbc-api-scala\"   %   \"{{version}}\" , \n   //here goes the driver dependency  )",
            "title": "SBT"
        },
        {
            "location": "/scala/gettingstarted/#gradle",
            "text": "For Gradle projects, add the following to the  dependencies  section of  build.gradle :  Scala 2.12  compile   group:   'io.rdbc' ,   name:   'rdbc-api-scala_2.12' ,   version:   '{{version}}'  compile   //here goes the driver dependency   Scala 2.11  compile   group:   'io.rdbc' ,   name:   'rdbc-api-scala_2.11' ,   version:   '{{version}}'  compile   //here goes the driver dependency",
            "title": "Gradle"
        },
        {
            "location": "/scala/gettingstarted/#maven",
            "text": "For Maven projects, add the following to the  dependencies  element of  pom.xml :  Scala 2.12  <dependency> \n   <groupId> io.rdbc </groupId> \n   <artifactId> rdbc-api-scala_2.12 </artifactId> \n   <version> {{version}} </version>  </dependency>  <dependency> \n   <!-- here goes the driver dependency -->  </dependency>   Scala 2.11  <dependency> \n   <groupId> io.rdbc </groupId> \n   <artifactId> rdbc-api-scala_2.11 </artifactId> \n   <version> {{version}} </version>  </dependency>  <dependency> \n   <!-- here goes the driver dependency -->  </dependency>",
            "title": "Maven"
        },
        {
            "location": "/scala/gettingstarted/#working-with-scala-futures",
            "text": "Since all rdbc API methods that perform I/O return Scala's  Future s you'll\nneed a knowledge on how to write asynchronous code using them. Throughout this \ndocumentation it is assumed that the reader has a basic knowledge about  Future \ntrait. If you're new to this concept you may find these resources useful:   The Neophyte's Guide to Scala  Official documentation",
            "title": "Working with Scala Futures"
        },
        {
            "location": "/scala/gettingstarted/#a-hello-world-application",
            "text": "It's time for a small but complete example of rdbc API usage. A snippet below\ninserts a \"Hello world!\" greeting into a  messages  database table.   A table with the following definition is assumed to exist:  create   table   messages ( txt   varchar ( 100 ))   And here's the actual code snippet:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26 import   io.rdbc.sapi._  import   scala.concurrent.ExecutionContext.Implicits.global  import   scala.concurrent.duration._  import   scala.concurrent. { Await ,   Future }  import   scala.util. { Failure ,   Success }  object   HelloRdbc   extends   App   { \n\n   val   connFactory :   ConnectionFactory   =   ??? \n\n   val   greeting   =   \"Hello World!\" \n   val   insertFut :   Future [ Long ]   =   connFactory . withConnection   {   conn   => \n     conn \n       . statement ( sql \"insert into messages(txt) values ($greeting)\" ) \n       . executeForRowsAffected () \n   }. andThen   { \n     case   Success ( count )   =>   println ( s\"inserted  $count  greeting(s)\" ) \n     case   Failure ( ex )   =>   ex . printStackTrace () \n   } \n\n   Await . ready ( \n     insertFut . transformWith ( _   =>   connFactory . shutdown ()), \n     10. seconds \n   )  }    In this very simple application:    At line  10  a\n    ConnectionFactory \n   coming from a driver package should be instantiated. Each rdbc driver provides\n   an implementation of this trait that allows to estabilish a connection to a database.\n    ConnectionFactory  implementation and classes needed for its configuration should\n   be the only classes directly used from the driver package.    At line  13  a connection to the database is requested to be estabilished - \n   when that happens, a function passed as a code block is executed.    In this code block, at line  15  a prepared statement is requested to be\n   created using a\n    sql \n    string interpolator \n   which passes a  greeting  string argument to it.    The statement is requested to be executed at line  16  and\n   to return number of affected rows.    When the database operation finishes and the connection is released, at line\n    17  the  Future 's result is handled: number of affected rows is printed in\n   case of a success or a stack trace is printed in case of an error.    None of the database calls block the executing thread - all of them return\n    Future s that are then chained. The only statement that blocks starts at line\n    22  when the application waits for operations requested earlier to complete.\n   Because this demo is just a simple console application, we need to block the\n   thread somewhere to wait for a moment that the application can exit.",
            "title": "A \"Hello world\" application"
        },
        {
            "location": "/scala/gettingstarted/#scaladoc",
            "text": "You can browse Scaladoc using javadoc.io site  here . The site\nallows to switch between Scala versions and rdbc versions.",
            "title": "Scaladoc"
        },
        {
            "location": "/scala/core_concepts/",
            "text": "There are a couple of core concepts that the API is built upon:\n\n\n\n\n\n\nAsynchronous processing\n\n\nEvery operation that involves I/O with the database is asynchronous. Methods\n return \nFuture\n or Reactive Stream's \nPublisher\n instances.\n\n\n\n\n\n\nThread safety\n\n\nrdbc API requires that its implementations must be thread-safe. You are free\n to share class instances among threads, even those that are mutable.\n\n\n\n\n\n\nNull safety\n\n\nSQL \nNULL\n values are represented as \nOption\n instances. Scala \nnull\n doesn't\n have to be used when working with the API.",
            "title": "Core concepts"
        },
        {
            "location": "/scala/connection/",
            "text": "Connecting to a database\n\u00b6\n\n\nTo connect to a database you first need to get a hold on \nConnectionFactory\n\nimplementation provided by a rdbc driver. Consult the driver's documentation on how to\ninstantiate and configure \nConnectionFactory\n it provides. \n\n\nTo connect to a database means to obtain \nConnection\n instance. Once you have\nthe factory, you have the following options on how to get the connection:\n\n\nManually opening and releasing a connection\n\u00b6\n\n\nConnection factory provides \n\nconnection\n\nmethod that simply returns a \nFuture\n holding a \nConnection\n. A connection\nobtained this way must be then released manually using \n\nrelease\n\nmethod. Here's the example usage:\n\n\nimport\n \nio.rdbc.sapi._\n\n\nimport\n \nio.rdbc.util.Futures._\n\n\n\nval\n \ncf\n:\n \nConnectionFactory\n \n=\n \n???\n\n\n\nval\n \nresult\n \n=\n \ncf\n.\nconnect\n().\nflatMap\n \n{\n \nconn\n \n=>\n\n   \n/* use the connection */\n\n   \n???\n\n\n}.\nandThenF\n \n{\n \ncase\n \n_\n \n=>\n\n   \nconn\n.\nrelease\n()\n\n\n}\n\n\n\n\n\n\nandThenF\n\nfuture combinator provided by\n\nrdbc utilities\n\npackage is like a standard \nandThen\n but partial function passed to it returns\na \nFuture\n and the chain can proceed only when this future completes. Relation between\n\nandThenF\n and \nandThen\n is analogous to the relation between \nflatMap\n and \nmap\n.\n\n\nUsing the loan pattern\n\u00b6\n\n\nEven if you haven't heard about the loan pattern you probably know what it is.\nConnection factory provides\n\nwithConnection\n\nmethod that executes a block of code in the context of a database connection and\nreleases the connection afterwards. It looks like this:\n\n\nimport\n \nio.rdbc.sapi._\n\n\n\nval\n \ncf\n:\n \nConnectionFactory\n \n=\n \n???\n\n\n\nval\n \nresult\n \n=\n \ncf\n.\nwithConnection\n \n{\n \nconn\n \n=>\n\n   \n/* use the connection */\n\n   \n???\n\n\n}\n\n\n\n\n\n\nThe above example is equivalent to the one from the\n\nprevious paragraph\n.\n\n\nTransaction management\n\u00b6\n\n\nIn rdbc, \nConnection\n provides facilities to manage database transactions. Using SQL\nto manage transaction state by issuing commands like \nBEGIN\n or \nROLLBACK\n is\nnot allowed. If you don't manage transaction at all, every SQL statement will\nbe executed in its own transaction. Following sections describe ways of managing\ntransactions.\n\n\nManual\n\u00b6\n\n\nManaging transaction manually means using the three methods provided by \nConnection\n\ntrait:\n\nbeginTx\n,\n\ncommitTx\n\nand \nrollbackTx\n. \nEach of these methods return a \nFuture\n of \nUnit\n \u2014 there is no dedicated \ntrait or class representing a transaction. Similar to manual handling of connecting\nand disconnecting from the database, manual transaction management is kind of\ncumbersome. When you don't need the flexibility provided by the three methods,\nuse the transactional loan pattern described below.\n\n\nUsing the transactional loan pattern\n\u00b6\n\n\nConnection\n trait provides\n\nwithTransaction\n\nmethod which allows to execute a block of code in a context of a newly started\ntransaction. If a \nFuture\n returned by the block of code is successful, the\ntransaction will be committed \u2014 if it fails, the transaction will be rolled\nback:\n\n\nimport\n \nio.rdbc.sapi._\n\n\n\nval\n \ncf\n:\n \nConnectionFactory\n \n=\n \n???\n\n\n\nval\n \nresult\n \n=\n \ncf\n.\nwithConnection\n \n{\n \nconn\n \n=>\n\n   \nconn\n.\nwithTransaction\n \n{\n\n    \n/* use the connection in a context of the transaction */\n\n    \n???\n\n   \n}\n\n\n}\n\n\n\n\n\n\nIf any error occurs when rolling back the transaction, this error will be reported\nto the execution context and the original error causing the rollback will be returned.\n\n\nIt's a common use case to connect to the database and execute just a single\ntransaction. This use case is covered by \n\nwithTransaction\n\nmethod provided by a \nConnectionFactory\n. Above snippet could be simplified as follows:\n\n\nimport\n \nio.rdbc.sapi._\n\n\n\nval\n \ncf\n:\n \nConnectionFactory\n \n=\n \n???\n\n\n\nval\n \nresult\n \n=\n \ncf\n.\nwithTransaction\n \n{\n \nconn\n \n=>\n\n    \n/* use the connection in a context of the transaction */\n\n    \n???\n\n\n}\n\n\n\n\n\n\nValidation\n\u00b6\n\n\nSometimes, it may be useful to verify whether already open connection is \"valid\",\ni.e. whether it can still execute queries. A connection may get broken because of\na number of reasons including network-related problems. To check whether the connection\nis usable, use\n\nvalidate\n\nmethod.\n\n\nConnection can also be validated by executing any query but using \nvalidate\n is\na preferred way since it can leverage a vendor-specific way of validating the\nconnection with a minimal overhead.\n\n\nConcurrent operations\n\u00b6\n\n\nAs every other rdbc class, \nConnection\n is thread-safe. However, it doesn't mean\nthat multiple threads can execute queries using the same connection at the same\ntime. Only one operation can be executed at any given time. When some thread tries\nto use a non-idle connection, resulting \nFuture\n fails with\n\nIllegalSessionStateException\n.\nException to this rule is \n\nforceRelease\n\nmethod which can be used regardless of whether connection is idle or not.\n\n\nExample below demonstrates an invalid code which can fail with \nIllegalSessionStateException\n:\n\n\n1\n2\n3\n4\n5\n6\n7\n8\nimport\n \nio.rdbc.sapi._\n\n\n\nval\n \ncf\n:\n \nConnectionFactory\n \n=\n \n???\n\n\n\ncf\n.\nwithConnection\n \n{\n \nconn\n \n=>\n\n    \nconn\n.\nvalidate\n().\nforeach\n(\nvalid\n \n=>\n \nprintln\n(\ns\"1. valid = \n$valid\n\"\n))\n\n\n    \nconn\n.\nvalidate\n().\nforeach\n(\nvalid\n \n=>\n \nprintln\n(\ns\"2. valid = \n$valid\n\"\n))\n\n\n}\n\n\n\n\n\n\n\nFuture\n returned by statement at line \n7\n may fail because connection may still\nbe busy executing a request from line \n6\n. You can be sure though that the connection\nwill start executing the first request (line \n6\n) before the second (line \n7\n)\n\u2014 there is a happens-before relation there.\n\n\nTo make the above code safe, it could be rewritten like this:\n\n\nimport\n \nio.rdbc.sapi._\n\n\n\nval\n \ncf\n:\n \nConnectionFactory\n \n=\n \n???\n\n\n\ncf\n.\nwithConnection\n \n{\n \nconn\n \n=>\n\n    \nconn\n.\nvalidate\n().\nforeach\n(\nvalid\n \n=>\n \nprintln\n(\ns\"1. valid = \n$valid\n\"\n))\n\n    \n.\nandThen\n \n{\n \n_\n \n=>\n\n       \nconn\n.\nvalidate\n().\nforeach\n(\nvalid\n \n=>\n \nprintln\n(\ns\"2. valid = \n$valid\n\"\n))\n\n    \n}\n\n\n}\n\n\n\n\n\n\nConnection\n also provides\n\nwatchForIdle\n\nmethod returning future which completes when connection becomes idle. Snippet below\nis safe from failing with \nIllegalSessionStateException\n.\n\n\nimport\n \nio.rdbc.sapi._\n\n\n\nval\n \ncf\n:\n \nConnectionFactory\n \n=\n \n???\n\n\n\ncf\n.\nwithConnection\n \n{\n \nconn\n \n=>\n\n    \nconn\n.\nvalidate\n().\nforeach\n(\nvalid\n \n=>\n \nprintln\n(\ns\"1. valid = \n$valid\n\"\n))\n\n    \nconn\n.\nwatchForIdle\n.\nandThen\n \n{\n \n_\n \n=>\n\n        \nconn\n.\nvalidate\n().\nforeach\n(\nvalid\n \n=>\n \nprintln\n(\ns\"2. valid = \n$valid\n\"\n))\n\n    \n}\n\n\n}\n\n\n\n\n\n\nConnection pooling\n\u00b6\n\n\nEstabilishing a new connection every time an interaction with the database is needed\nis expensive performance-wise. There usually is an overhead of initializing\nnew session. In order to avoid this problem you can use connection pooling.\n\n\nConnection pooling mechanism isn't really part of the API \u2014 to use pooling\nyou just need to use a special \nConnectionFactory\n implementation.\n\n\nHave a look at \nrdbc-pool\n project that\nprovides a \nConnectionFactory\n implementation capable of connection pooling.",
            "title": "Working with a connection"
        },
        {
            "location": "/scala/connection/#connecting-to-a-database",
            "text": "To connect to a database you first need to get a hold on  ConnectionFactory \nimplementation provided by a rdbc driver. Consult the driver's documentation on how to\ninstantiate and configure  ConnectionFactory  it provides.   To connect to a database means to obtain  Connection  instance. Once you have\nthe factory, you have the following options on how to get the connection:",
            "title": "Connecting to a database"
        },
        {
            "location": "/scala/connection/#manually-opening-and-releasing-a-connection",
            "text": "Connection factory provides  connection \nmethod that simply returns a  Future  holding a  Connection . A connection\nobtained this way must be then released manually using  release \nmethod. Here's the example usage:  import   io.rdbc.sapi._  import   io.rdbc.util.Futures._  val   cf :   ConnectionFactory   =   ???  val   result   =   cf . connect (). flatMap   {   conn   => \n    /* use the connection */ \n    ???  }. andThenF   {   case   _   => \n    conn . release ()  }   andThenF \nfuture combinator provided by rdbc utilities \npackage is like a standard  andThen  but partial function passed to it returns\na  Future  and the chain can proceed only when this future completes. Relation between andThenF  and  andThen  is analogous to the relation between  flatMap  and  map .",
            "title": "Manually opening and releasing a connection"
        },
        {
            "location": "/scala/connection/#using-the-loan-pattern",
            "text": "Even if you haven't heard about the loan pattern you probably know what it is.\nConnection factory provides withConnection \nmethod that executes a block of code in the context of a database connection and\nreleases the connection afterwards. It looks like this:  import   io.rdbc.sapi._  val   cf :   ConnectionFactory   =   ???  val   result   =   cf . withConnection   {   conn   => \n    /* use the connection */ \n    ???  }   The above example is equivalent to the one from the previous paragraph .",
            "title": "Using the loan pattern"
        },
        {
            "location": "/scala/connection/#transaction-management",
            "text": "In rdbc,  Connection  provides facilities to manage database transactions. Using SQL\nto manage transaction state by issuing commands like  BEGIN  or  ROLLBACK  is\nnot allowed. If you don't manage transaction at all, every SQL statement will\nbe executed in its own transaction. Following sections describe ways of managing\ntransactions.",
            "title": "Transaction management"
        },
        {
            "location": "/scala/connection/#manual",
            "text": "Managing transaction manually means using the three methods provided by  Connection \ntrait: beginTx , commitTx \nand  rollbackTx . \nEach of these methods return a  Future  of  Unit  \u2014 there is no dedicated \ntrait or class representing a transaction. Similar to manual handling of connecting\nand disconnecting from the database, manual transaction management is kind of\ncumbersome. When you don't need the flexibility provided by the three methods,\nuse the transactional loan pattern described below.",
            "title": "Manual"
        },
        {
            "location": "/scala/connection/#using-the-transactional-loan-pattern",
            "text": "Connection  trait provides withTransaction \nmethod which allows to execute a block of code in a context of a newly started\ntransaction. If a  Future  returned by the block of code is successful, the\ntransaction will be committed \u2014 if it fails, the transaction will be rolled\nback:  import   io.rdbc.sapi._  val   cf :   ConnectionFactory   =   ???  val   result   =   cf . withConnection   {   conn   => \n    conn . withTransaction   { \n     /* use the connection in a context of the transaction */ \n     ??? \n    }  }   If any error occurs when rolling back the transaction, this error will be reported\nto the execution context and the original error causing the rollback will be returned.  It's a common use case to connect to the database and execute just a single\ntransaction. This use case is covered by  withTransaction \nmethod provided by a  ConnectionFactory . Above snippet could be simplified as follows:  import   io.rdbc.sapi._  val   cf :   ConnectionFactory   =   ???  val   result   =   cf . withTransaction   {   conn   => \n     /* use the connection in a context of the transaction */ \n     ???  }",
            "title": "Using the transactional loan pattern"
        },
        {
            "location": "/scala/connection/#validation",
            "text": "Sometimes, it may be useful to verify whether already open connection is \"valid\",\ni.e. whether it can still execute queries. A connection may get broken because of\na number of reasons including network-related problems. To check whether the connection\nis usable, use validate \nmethod.  Connection can also be validated by executing any query but using  validate  is\na preferred way since it can leverage a vendor-specific way of validating the\nconnection with a minimal overhead.",
            "title": "Validation"
        },
        {
            "location": "/scala/connection/#concurrent-operations",
            "text": "As every other rdbc class,  Connection  is thread-safe. However, it doesn't mean\nthat multiple threads can execute queries using the same connection at the same\ntime. Only one operation can be executed at any given time. When some thread tries\nto use a non-idle connection, resulting  Future  fails with IllegalSessionStateException .\nException to this rule is  forceRelease \nmethod which can be used regardless of whether connection is idle or not.  Example below demonstrates an invalid code which can fail with  IllegalSessionStateException :  1\n2\n3\n4\n5\n6\n7\n8 import   io.rdbc.sapi._  val   cf :   ConnectionFactory   =   ???  cf . withConnection   {   conn   => \n     conn . validate (). foreach ( valid   =>   println ( s\"1. valid =  $valid \" ))       conn . validate (). foreach ( valid   =>   println ( s\"2. valid =  $valid \" ))  }    Future  returned by statement at line  7  may fail because connection may still\nbe busy executing a request from line  6 . You can be sure though that the connection\nwill start executing the first request (line  6 ) before the second (line  7 )\n\u2014 there is a happens-before relation there.  To make the above code safe, it could be rewritten like this:  import   io.rdbc.sapi._  val   cf :   ConnectionFactory   =   ???  cf . withConnection   {   conn   => \n     conn . validate (). foreach ( valid   =>   println ( s\"1. valid =  $valid \" )) \n     . andThen   {   _   => \n        conn . validate (). foreach ( valid   =>   println ( s\"2. valid =  $valid \" )) \n     }  }   Connection  also provides watchForIdle \nmethod returning future which completes when connection becomes idle. Snippet below\nis safe from failing with  IllegalSessionStateException .  import   io.rdbc.sapi._  val   cf :   ConnectionFactory   =   ???  cf . withConnection   {   conn   => \n     conn . validate (). foreach ( valid   =>   println ( s\"1. valid =  $valid \" )) \n     conn . watchForIdle . andThen   {   _   => \n         conn . validate (). foreach ( valid   =>   println ( s\"2. valid =  $valid \" )) \n     }  }",
            "title": "Concurrent operations"
        },
        {
            "location": "/scala/connection/#connection-pooling",
            "text": "Estabilishing a new connection every time an interaction with the database is needed\nis expensive performance-wise. There usually is an overhead of initializing\nnew session. In order to avoid this problem you can use connection pooling.  Connection pooling mechanism isn't really part of the API \u2014 to use pooling\nyou just need to use a special  ConnectionFactory  implementation.  Have a look at  rdbc-pool  project that\nprovides a  ConnectionFactory  implementation capable of connection pooling.",
            "title": "Connection pooling"
        },
        {
            "location": "/scala/statements/",
            "text": "Statement types\n\u00b6\n\n\nStatements are a core feature of rdbc API. They represent SQL pieces that are sent\nto a database for execution along with arguments, if any. There are two types\nof statements in rdbc: template statements and executable statements. Template\nstatements can't be executed right away. To execute them you first need to bind argument\nfor every parameter they declare. When filled with arguments, template statements\ncreate executable statements. Statements in rdbc are a representation database engine's\n\nprepared statements\n.\n\n\nSyntax\n\u00b6\n\n\nThere isn't much of a syntax to describe. The only thing in a statement syntax\nthat rdbc adds to SQL is how parameters are defined. There are two kinds of\nparameters: named and positional.\n\n\nNamed parameters\n\u00b6\n\n\nNamed parameters:\n\n\n\n\nare alphanumeric identifiers,\n\n\ncan be defined inside a query by prepending parameter identifier with a colon,\n\n\ncan be placed only where database engine expects parameters as defined\n     by a database engine's prepared statement syntax,\n\n\nare ignored inside varchar literals, column aliases, comments, etc.,\n\n\ncan be referenced by their name or by index (position).\n\n\n\n\nIn the following statement just one parameter is declared: \nlogin\n:\n\n\nselect\n \n*\n \nfrom\n \nusers\n \nwhere\n \nusername\n \n=\n \n:\nlogin\n\n\n\n\n\n\nA parameter can be used in multiple places. Statement below defines a single\nparameter: \nname\n, but this parameter is used in two places:\n\n\nselect\n \n*\n \nfrom\n \nusers\n \nwhere\n \nfirst_name\n \n=\n \n:\nname\n \nor\n \nmiddle_name\n \n=\n \n:\nname\n \n\n\n\n\n\nThe statement below doesn't declare any parameters. \"fname\" is inside a varchar\nliteral and \"mname\" is part of a comment.\n\n\nselect\n \n*\n \nfrom\n \nusers\n \nwhere\n \nfirst_name\n \n=\n \n':fname'\n \n-- or middle_name = :mname\n\n\n\n\n\n\nPositional parameters\n\u00b6\n\n\nPositional parameters:\n\n\n\n\ncan be defined inside a query by placing a question mark: \n?\n,\n\n\ncan be placed only where database engine expects parameters as defined\n     by a database engine's prepared statement syntax,\n\n\nare ignored inside varchar literals, column aliases, comments, etc.,\n\n\ncan be referenced only by their index (position).\n\n\n\n\nThe following example statement uses two positional parameters:\n\n\nselect\n \n*\n \nfrom\n \nusers\n \nwhere\n \nfirst_name\n \n=\n \n?\n \nor\n \nmiddle_name\n \n=\n \n?\n \n\n\n\n\n\nThe statement below doesn't declare any parameters. The first question mark is \ninside a varchar literal and the second is part of a comment.\n\n\nselect\n \n*\n \nfrom\n \nusers\n \nwhere\n \nfirst_name\n \n=\n \n'?'\n \n-- or middle_name = ?\n\n\n\n\n\n\nCreating statements\n\u00b6\n\n\nBare strings\n\u00b6\n\n\nStatement can be created using a bare string and then in a separate step be\nfilled with arguments for execution. There is a \n\nstatement\n\nmethod defined in \nConnection\n trait that accepts a string, and returns a\n\nStatement\n\ninstance bound to the connection:\n\n\nval\n \nstmt\n:\n \nStatement\n \n=\n \nconn\n.\nstatement\n(\n\n \n\"select * from users \"\n \n+\n\n \n\"where (first_name = :name or last_name = :name) and age = :age\"\n\n\n)\n\n\n\n\n\n\nOnce you have a \nStatement\n object, you can bind values to its parameters:\n\n\n\n\n\n\nby name\n\n\nTo bind values to parameters by name, use \nStatement\n's \nbind\n method that\naccepts a sequence of \n(String, Any)\n tuples, one for each parameter. Above\nstatement's parameters could be bound to values like this:\n\nstmt\n.\nbind\n(\n\"name\"\n \n->\n \n\"Casey\"\n,\n \n\"age\"\n \n->\n \n30\n)\n.\n\n\nIf you don't provide all parameter values when binding, a\n\nMissingParamValException\n\nwill be thrown. If you provide value for a parameter that wasn't declared by\nthe query,\n\nNoSuchParamException\n\nwill be thrown.\n\n\nBinding by name is available only if name parameters were used.\n\n\n\n\n\n\nby index\n\n\nThere is a possibility to bind values to parameters by index - i.e. just\nprovide a list of values and these values will be matched to every parameter\noccurrence. Arguments can be bound to the above query like this:\n\nstmt\n.\nbind\n(\n\"Casey\"\n,\n \n\"Casey\"\n,\n \n30\n)\n.\n\n\nIf you provide too many parameters\n\nTooManyParamsException\n\nwill be thrown.\nIf you provide too few parameters\n\nMissingParamValException\n\nwill be thrown.\n\n\nThis method of binding is the only one available if you used positional parameters.\n\n\n\n\n\n\nIf your statement doesn't declare any parameters, use \nbind\n method without\npassing any arguments to it.\n\n\nString interpolator\n\u00b6\n\n\nCreating statements using simple strings and binding values to parameters in\na separate step is flexible but this flexibility is not really needed in most\ncases. A preferred way of creating statements is by using\n\nsql\n\n\nstring interpolator\n.\n\n\nYou can get \nsql\n interpolator into scope either by importing everything from\n\nio.rdbc.sapi\n package by \nimport\n \nio.rdbc.sapi._\n statement or selectively by\n\nimport\n \nio.rdbc.sapi.SqlInterpolator._\n statement.\n\n\nOnce you have it in scope, you can use it to declare parameters and bind values\nto them in one step, like this:\n\n\nval\n \nconn\n:\n \nConnection\n \n=\n \n???\n\n\n\ndef\n \nfindUsersStmt\n(\nname\n:\n \nString\n)\n:\n \nExecutableStatement\n \n=\n \n{\n\n   \nconn\n.\nstatement\n(\nsql\n\"select * from users where name = $name\"\n)\n\n\n}\n\n\n\n\n\n\nAs you can see, when \nsql\n interpolator is used \nConnection\n's \nstatement\n method\nproduces \nExecutableStatement\n, so the statement already has values\nbound to its parameters. The above example is equivalent to the following, somewhat\nless concise snippet:\n\n\ndef\n \nfindUsersStmt\n(\nname\n:\n \nString\n)\n:\n \nExecutableStatement\n \n=\n \n{\n   \n    \nconn\n.\nstatement\n(\n\"select * from users where name = ?\"\n)\n\n        \n.\nbindByIdx\n(\nname\n)\n\n\n}\n\n\n\n\n\n\n\n\nSQL injection safety\n\n\nImportant thing to understand is that when using \nsql\n interpolator you're still\nsafe from creating SQL injection vulnerability. Even though it may look like\nthat, parameter values are \nnot\n passed in to the database as literals\nconcatenated with the rest of the SQL.\n\n\n\n\nSQL parts created by \nsql\n interpolator can be concatenated in the same way you\nwould concatenate plain strings:\n\n\ndef\n \nfindUsersStmt\n(\nname\n:\n \nString\n,\n \nage\n:\n \nInt\n)\n:\n \nExecutableStatement\n \n=\n \n{\n\n  \nconn\n.\nstatement\n(\n\n   \nsql\n\"select * from users \"\n \n+\n\n   \nsql\n\"where (first_name = $name or last_name = $name) and age = $age\"\n\n  \n)\n\n\n}\n\n\n\n\n\n\nDynamic SQL\n\u00b6\n\n\nSometimes, most notably in tests or some one-time use scripts, it may be useful\nto create SQL dynamically, like this:\n\n\ndef\n \nstmt\n(\ntable\n:\n \nString\n,\n \nname\n:\n \nString\n)\n:\n \nFutureExecutableStatement\n \n=\n \n{\n\n  \nconn\n.\nstatement\n(\ns\"select * from \n$table\n where name = :name\"\n)\n\n      \n.\nbind\n(\n\"name\"\n \n->\n \nname\n)\n\n\n}\n\n\n\n\n\n\nIf you want to create SQL dynamically and still benefit from \nsql\n interpolator\nfeatures, use \n#$\n prefix for dynamic parts, like this:\n\n\ndef\n \nsql\n(\ntable\n:\n \nString\n,\n \nname\n:\n \nString\n)\n:\n \nExecutableStatement\n \n=\n \n{\n\n  \nconn\n.\nstatement\n(\nsql\n\"select * from #$table where name = $name\"\n)\n\n\n}\n\n\n\n\n\n\nIn the above example, only \n$name\n is a statement parameter, \n#$table\n will be\nsimply replaced by \ntable\n method parameter value.\n\n\nOptions\n\u00b6\n\n\nWhen creating a statement you can provide options that can tweak statement's\nbehavior. To pass options, use \nConnection\n's \nstatement\n methods that accept\nsecond argument of\n\nStatementOptions\n type.\n\n\nThe list below contains currently supported options:\n\n\n\n\n\n\n\n\nOption:\n \ngeneratedKeyCols\n\n\nControls statement behavior regarding returning keys generated by the\n database when issuing update or insert statements.\n\n\nPossible values\n:\n\n\n\n\nKeyColumns.All\n \u2014 all columns with generated keys will be returned\n\n\nKeyColumns.None\n \u2014 no columns with generated keys will be returned\n\n\nKeyColumns.named(cols: String*)\n \u2014 only columns listed by name will be returned\n\n\n\n\nDefault value\n: \nKeyColumns.None\n\n\n\n\n\n\n\n\nStatementOptions\n is a case class and in its companion object there is \nDefault\n\ninstance of it with the default option values. You can use this instance to\ntweak only some of the options using built-in \ncopy\n method:\n\n\nconn\n.\nstatement\n(\n\n  \nsql\n\"insert into users(name) values ($name)\"\n,\n\n  \nDefault\n.\ncopy\n(\noption1\n \n=\n \nvalue1\n,\n \noption2\n \n=\n \nvalue2\n)\n\n\n)\n\n\n\n\n\n\nExecuting statements\n\u00b6\n\n\nOnce you have an \nExecutableStatement\n instance, you can execute it in a couple\nof different ways. The method of execution controls in what shape you get the\nresults from the database. Paragraphs below describe methods of executing statements.\n\n\nExecuting for a result set\n\u00b6\n\n\nArguably the simplest method of execution that returns results is to execute\nstatement for a result set. To do this, use \nExecutableStatement\n's\n\nexecuteForSet\n\nmethod that returns \nFuture\n of\n\nResultSet\n.\n\n\nResultSet\n gives you access to the rows as well as to the metadata like warnings\nissued by the DB engine, columns metadata and count of rows affected by the statement.\nIt also implements \nTraversable\n trait providing a convenience method of traversing\nthrough the rows.\n\n\nExecuting for set is simple, but be aware that for bigger sets you may encounter\n\nOutOfMemoryError\ns. All results are stored in memory, there is no paging of any\nkind. If you want to avoid this sort of problems, consider\n\nstreaming\n the results.\n\n\nFor the documentation on how to work with the resulting rows see\n\nResult Rows\n chapter.\n\n\ndef\n \nselectUserAge\n(\nname\n:\n \nString\n)\n:\n \nFuture\n[\nResultSet\n]\n \n=\n \n{\n\n  \nconn\n.\nstatement\n(\nsql\n\"select age from users where name = $name\"\n).\nexecuteForSet\n()\n\n\n}\n\n\n\n\n\n\nStreaming results\n\u00b6\n\n\nTo stream results from the database, use \nExecutableStatement\n's\n\nstream\n\nmethod. This method returns\n\nRowPublisher\n\ninstance which implements reactive stream's\n\nPublisher\n\ninterface. \nstream\n method never throws exceptions \u2014 failures are reported by\nthe returned publisher.\n\n\nItems published are rows represented by \nRow\n trait. For the documentation on how\nto work with the resulting rows see \nResult Rows\n chapter.\n\n\nHere are a couple of things to know when working with streams:\n\n\n\n\nstatement execution is deferred until publisher is subscribed to,\n\n\na publisher can be subscribed to only once,\n\n\nafter \nstream\n method is invoked, connection is considered busy and can be used\n     for other queries only after the stream completes or is cancelled,\n\n\ncancel is an asynchronous operation and Reactive Streams specification doesn't\n     provide a way of notifying a client that cancel operation completed. If clients\n     want to use the connection after stream cancellation, they must watch for\n     publisher's \ndone\n \nFuture\n completion before requesting any\n     subsequent operations.\n\n\n\n\nRowPublisher\n instance, through its members, gives access to number\nof affected rows, warnings returned by the database and row metadata.\n\n\nProcessing streams is out of scope of this manual, for details please refer to\ndocumentation of Reactive Streams compatible libraries that are built to\nfacilitate this, like\n\nAkka stream\n or\n\nMonix\n.\n\n\nExamples (which release the connection on stream termination):\n\n\nimport\n \nakka.stream.scaladsl.\n{\nSource\n,\n \nSink\n}\n\n\nimport\n \nakka.NotUsed\n\n\n\nval\n \nsource\n:\n \nSource\n[\nRow\n, \nNotUsed\n]\n \n=\n \n{\n\n  \nSource\n.\nfromPublisher\n(\n\n    \nconn\n.\nstatement\n(\nsql\n\"select name from users\"\n).\nstream\n()\n\n  \n).\nalsoTo\n(\nSink\n.\nonComplete\n(\n_\n \n=>\n \nconn\n.\nrelease\n()))\n\n\n}\n\n\n\n\n\n\nimport\n \nmonix.reactive.Observable\n\n\nimport\n \nmonix.eval.Task\n\n\n\nval\n \nobs\n:\n \nObservable\n[\nRow\n]\n \n=\n \n{\n\n  \nObservable\n.\nfromReactivePublisher\n(\n\n    \nconn\n.\nstatement\n(\nsql\n\"select name from users\"\n).\nstream\n()\n\n  \n).\ndoOnTerminateEval\n(\n_\n \n=>\n \nTask\n.\nfromFuture\n(\nconn\n.\nrelease\n()))\n\n\n}\n\n\n\n\n\n\nExecuting ignoring results\n\u00b6\n\n\nIn many cases clients are not interested in any result of statement execution\nother than simple \"success\" or \"failure\" information. This is often the case\nfor \ninsert\n, \nupdate\n and \ndelete\n commands. This use case is covered by\n\nExecutableStatement\n's \nexecute\n method which returns \nFuture\n of \nUnit\n.\n\n\nExample:\n\n\ndef\n \ninsertUser\n(\nname\n:\n \nString\n)\n:\n \nFuture\n[\nUnit\n]\n \n=\n \n{\n\n  \nconn\n.\nstatement\n(\nsql\n\"insert into users(name) values ($name)\"\n).\nexecute\n()\n\n\n}\n\n\n\n\n\n\nExecuting for a single row and for a value\n\u00b6\n\n\nIt is a common use case to expect just a single row to be returned by a query.\nFor instance, when querying by a primary key. This can be easily achieved by\nusing \nExecutableStatement\n's\n\nexecuteForFirstRow\n\nmethod which returns a \nFuture\n of \nOption[Row]\n. Returned \nOption\n is \nNone\n\nin case when query doesn't return any results, otherwise, the first row is\nreturned as a \nSome\n.\n\n\nExample:\n\n\ndef\n \nfindUser\n(\nlogin\n:\n \nString\n)\n:\n \nFuture\n[\nOption\n[\nRow\n]]\n \n=\n \n{\n\n  \nconn\n.\nstatement\n(\nsql\n\"select * from users where login = $login\"\n)\n\n      \n.\nexecuteForFirstRow\n()\n\n\n}\n\n\n\n\n\n\nSometimes, not even a single row is needed by a client, only a single column\nvalue, like user's name when searching by login.\n\nexecuteForValue\n\nmethod comes in handy in these kind of situations. The method accepts  a function\nthat is supposed to extract this single value from a returned row, if any.\n\n\nSee the example below:\n\n\ndef\n \nfindUsersName\n(\nlogin\n:\n \nString\n)\n:\n \nFuture\n[\nOption\n[\nString\n]]\n \n=\n \n{\n\n  \nconn\n.\nstatement\n(\nsql\n\"select name from users where login = $login\"\n)\n\n      \n.\nexecuteForValue\n(\nr\n \n=>\n \nr\n.\nstr\n(\n\"name\"\n))\n\n\n}\n\n\n\n\n\n\nFor the documentation on how to work with the resulting rows see\n\nResult Rows\n chapter.\n\n\nExecuting for rows affected\n\u00b6\n\n\nWhen executing insert, update or delete statements it may be good to know\nhow many rows were affected by the execution. A number of affected rows can be\nobtained when executing for set or by streaming but if it's the only information\nthat is needed use \nExecutableStatement\n's \n\nexecuteForRowsAffected\n\nmethod which returns a \nFuture\n of \nLong\n.\n\n\nSee the example below:\n\n\ndef\n \nupdateNames\n(\nname\n:\n \nString\n,\n \nage\n:\n \nInt\n)\n:\n \nFuture\n[\nLong\n]\n \n=\n \n{\n\n  \nconn\n.\nstatement\n(\nsql\n\"update users set name = $name where age = $age\"\n)\n\n      \n.\nexecuteForRowsAffected\n()\n\n\n}\n\n\n\n\n\n\nExecuting for generated key\n\u00b6\n\n\nIf you rely on primary keys being generated by the database when inserting\nnew records you'll need just this one key as a result of the execution. If you\nneed to get multiple generated values then use \nexecuteForStream\n, \nexecuteForSet\n\nor \nexecuteForFirstRow\n described above but for a single one, there is\n\nexecuteForKey\n\nmethod. This method executes a statement and returns the first column of the first\nreturned row (in most cases the result is going to be a single row with a single\ncolumn anyway). The method is parametrized by a type of the key.\n\n\nA method in the example below inserts a new user and returns a generated UUID key.\n\n\ndef\n \ninsertUser\n(\nname\n:\n \nString\n,\n \nage\n:\n \nInt\n)\n:\n \nFuture\n[\nUUID\n]\n \n=\n \n{\n\n  \nconn\n.\nstatement\n(\n\n        \nsql\n\"insert into users(name, age) values($name, $age)\"\n,\n\n        \nStatementOptions\n.\nReturnGenKeys\n\n  \n).\nexecuteForKey\n[\nUUID\n]()\n\n\n}\n\n\n\n\n\n\nStreaming statement arguments\n\u00b6\n\n\nrdbc provides an efficient way to execute statement repeatedly with many\nsets of arguments. \nStatement\n can subscribe to a stream of argument sets by\ninvoking \nstreamArgs\n or \nstreamArgsByIdx\n methods which accept Reactive Streams'\n\nPublisher\n. rdbc driver will back pressure the stream as needed.\n\n\nStreaming arguments can be used for statements that don't return any values.\nTechnically it is possible to stream arguments of SQL \nselect\ns but there are no\nmeans for the client to get the data back from the database.\n\n\nPositional and named parameters\n\u00b6\n\n\nEach stream element contains entire set of arguments that a given statement\nexpects. Clients have an alternative of using named and positional parameters:\n\nstreamArgs\n accepts a stream producing \nMap\n[\nString\n, \nAny\n]\n elements\n(named parameters) and \nstreamArgsByIdx\n indexed sequences of arguments\n(positional parameters).\n\n\nHandling failures\n\u00b6\n\n\nIf any error occurs in the middle of stream processing, the process will be aborted\nand \nFuture\n returned by the streaming method will fail too.\n\n\nExamples\n\u00b6\n\n\nCreating \nPublisher\n instances is out of scope of this manual, for details please\nrefer to documentation of Reactive Streams compatible libraries that are built to\nfacilitate this, like\n\nAkka stream\n or\n\nMonix\n. Examples below use simple streams backed by in\nmemory collections.\n\n\nStreaming named arguments with Akka:\n\n\nimport\n \nio.rdbc.sapi._\n\n\nimport\n \nakka.stream.scaladsl.Source\n\n\n\nval\n \nres\n:\n \nFuture\n[\nUnit\n]\n \n=\n \nconn\n.\nwithTransaction\n \n{\n\n  \nval\n \ndata\n:\n \nVector\n[\nMap\n[\nString\n, \nAny\n]]\n \n=\n \nVector\n(\n\n    \nMap\n(\n\"name\"\n \n->\n \n\"Robin\"\n,\n \n\"age\"\n \n->\n \n10\n),\n\n    \nMap\n(\n\"name\"\n \n->\n \n\"Alex\"\n,\n \n\"age\"\n \n->\n \n32\n),\n\n    \nMap\n(\n\"name\"\n \n->\n \n\"Casey\"\n,\n \n\"age\"\n \n->\n \n12\n)\n\n  \n)\n\n  \nval\n \npublisher\n \n=\n \nSource\n(\ndata\n).\nrunWith\n(\nSink\n.\nasPublisher\n(\nfanout\n \n=\n \nfalse\n))\n\n  \nval\n \nstmt\n \n=\n \nconn\n.\nstatement\n(\n\"insert into users(name, age) values (:name, :age)\"\n)\n\n  \nstmt\n.\nstreamArgs\n(\npublisher\n)\n\n\n}\n\n\n\n\n\n\nStreaming positional arguments with Akka:\n\n\nimport\n \nio.rdbc.sapi._\n\n\nimport\n \nakka.stream.scaladsl.Source\n\n\n\nval\n \nres\n:\n \nFuture\n[\nUnit\n]\n \n=\n \nconn\n.\nwithTransaction\n \n{\n\n  \nval\n \ndata\n:\n \nVector\n[\nVector\n[\nAny\n]]\n \n=\n \nVector\n(\n\n    \nVector\n(\n\"Robin\"\n,\n \n10\n),\n\n    \nVector\n(\n\"Alex\"\n,\n \n32\n),\n\n    \nVector\n(\n\"Casey\"\n,\n \n12\n)\n\n  \n)\n\n  \nval\n \npublisher\n \n=\n \nSource\n(\ndata\n).\nrunWith\n(\nSink\n.\nasPublisher\n(\nfanout\n \n=\n \nfalse\n))\n\n  \nval\n \nstmt\n \n=\n \nconn\n.\nstatement\n(\n\"insert into users(name, age) values (?, ?)\"\n)\n\n  \nstmt\n.\nstreamArgsByIdx\n(\npublisher\n)\n\n\n}",
            "title": "Statements"
        },
        {
            "location": "/scala/statements/#statement-types",
            "text": "Statements are a core feature of rdbc API. They represent SQL pieces that are sent\nto a database for execution along with arguments, if any. There are two types\nof statements in rdbc: template statements and executable statements. Template\nstatements can't be executed right away. To execute them you first need to bind argument\nfor every parameter they declare. When filled with arguments, template statements\ncreate executable statements. Statements in rdbc are a representation database engine's prepared statements .",
            "title": "Statement types"
        },
        {
            "location": "/scala/statements/#syntax",
            "text": "There isn't much of a syntax to describe. The only thing in a statement syntax\nthat rdbc adds to SQL is how parameters are defined. There are two kinds of\nparameters: named and positional.",
            "title": "Syntax"
        },
        {
            "location": "/scala/statements/#named-parameters",
            "text": "Named parameters:   are alphanumeric identifiers,  can be defined inside a query by prepending parameter identifier with a colon,  can be placed only where database engine expects parameters as defined\n     by a database engine's prepared statement syntax,  are ignored inside varchar literals, column aliases, comments, etc.,  can be referenced by their name or by index (position).   In the following statement just one parameter is declared:  login :  select   *   from   users   where   username   =   : login   A parameter can be used in multiple places. Statement below defines a single\nparameter:  name , but this parameter is used in two places:  select   *   from   users   where   first_name   =   : name   or   middle_name   =   : name    The statement below doesn't declare any parameters. \"fname\" is inside a varchar\nliteral and \"mname\" is part of a comment.  select   *   from   users   where   first_name   =   ':fname'   -- or middle_name = :mname",
            "title": "Named parameters"
        },
        {
            "location": "/scala/statements/#positional-parameters",
            "text": "Positional parameters:   can be defined inside a query by placing a question mark:  ? ,  can be placed only where database engine expects parameters as defined\n     by a database engine's prepared statement syntax,  are ignored inside varchar literals, column aliases, comments, etc.,  can be referenced only by their index (position).   The following example statement uses two positional parameters:  select   *   from   users   where   first_name   =   ?   or   middle_name   =   ?    The statement below doesn't declare any parameters. The first question mark is \ninside a varchar literal and the second is part of a comment.  select   *   from   users   where   first_name   =   '?'   -- or middle_name = ?",
            "title": "Positional parameters"
        },
        {
            "location": "/scala/statements/#creating-statements",
            "text": "",
            "title": "Creating statements"
        },
        {
            "location": "/scala/statements/#bare-strings",
            "text": "Statement can be created using a bare string and then in a separate step be\nfilled with arguments for execution. There is a  statement \nmethod defined in  Connection  trait that accepts a string, and returns a Statement \ninstance bound to the connection:  val   stmt :   Statement   =   conn . statement ( \n  \"select * from users \"   + \n  \"where (first_name = :name or last_name = :name) and age = :age\"  )   Once you have a  Statement  object, you can bind values to its parameters:    by name  To bind values to parameters by name, use  Statement 's  bind  method that\naccepts a sequence of  (String, Any)  tuples, one for each parameter. Above\nstatement's parameters could be bound to values like this: stmt . bind ( \"name\"   ->   \"Casey\" ,   \"age\"   ->   30 ) .  If you don't provide all parameter values when binding, a MissingParamValException \nwill be thrown. If you provide value for a parameter that wasn't declared by\nthe query, NoSuchParamException \nwill be thrown.  Binding by name is available only if name parameters were used.    by index  There is a possibility to bind values to parameters by index - i.e. just\nprovide a list of values and these values will be matched to every parameter\noccurrence. Arguments can be bound to the above query like this: stmt . bind ( \"Casey\" ,   \"Casey\" ,   30 ) .  If you provide too many parameters TooManyParamsException \nwill be thrown.\nIf you provide too few parameters MissingParamValException \nwill be thrown.  This method of binding is the only one available if you used positional parameters.    If your statement doesn't declare any parameters, use  bind  method without\npassing any arguments to it.",
            "title": "Bare strings"
        },
        {
            "location": "/scala/statements/#string-interpolator",
            "text": "Creating statements using simple strings and binding values to parameters in\na separate step is flexible but this flexibility is not really needed in most\ncases. A preferred way of creating statements is by using sql  string interpolator .  You can get  sql  interpolator into scope either by importing everything from io.rdbc.sapi  package by  import   io.rdbc.sapi._  statement or selectively by import   io.rdbc.sapi.SqlInterpolator._  statement.  Once you have it in scope, you can use it to declare parameters and bind values\nto them in one step, like this:  val   conn :   Connection   =   ???  def   findUsersStmt ( name :   String ) :   ExecutableStatement   =   { \n    conn . statement ( sql \"select * from users where name = $name\" )  }   As you can see, when  sql  interpolator is used  Connection 's  statement  method\nproduces  ExecutableStatement , so the statement already has values\nbound to its parameters. The above example is equivalent to the following, somewhat\nless concise snippet:  def   findUsersStmt ( name :   String ) :   ExecutableStatement   =   {    \n     conn . statement ( \"select * from users where name = ?\" ) \n         . bindByIdx ( name )  }    SQL injection safety  Important thing to understand is that when using  sql  interpolator you're still\nsafe from creating SQL injection vulnerability. Even though it may look like\nthat, parameter values are  not  passed in to the database as literals\nconcatenated with the rest of the SQL.   SQL parts created by  sql  interpolator can be concatenated in the same way you\nwould concatenate plain strings:  def   findUsersStmt ( name :   String ,   age :   Int ) :   ExecutableStatement   =   { \n   conn . statement ( \n    sql \"select * from users \"   + \n    sql \"where (first_name = $name or last_name = $name) and age = $age\" \n   )  }",
            "title": "String interpolator"
        },
        {
            "location": "/scala/statements/#dynamic-sql",
            "text": "Sometimes, most notably in tests or some one-time use scripts, it may be useful\nto create SQL dynamically, like this:  def   stmt ( table :   String ,   name :   String ) :   FutureExecutableStatement   =   { \n   conn . statement ( s\"select * from  $table  where name = :name\" ) \n       . bind ( \"name\"   ->   name )  }   If you want to create SQL dynamically and still benefit from  sql  interpolator\nfeatures, use  #$  prefix for dynamic parts, like this:  def   sql ( table :   String ,   name :   String ) :   ExecutableStatement   =   { \n   conn . statement ( sql \"select * from #$table where name = $name\" )  }   In the above example, only  $name  is a statement parameter,  #$table  will be\nsimply replaced by  table  method parameter value.",
            "title": "Dynamic SQL"
        },
        {
            "location": "/scala/statements/#options",
            "text": "When creating a statement you can provide options that can tweak statement's\nbehavior. To pass options, use  Connection 's  statement  methods that accept\nsecond argument of StatementOptions  type.  The list below contains currently supported options:     Option:   generatedKeyCols  Controls statement behavior regarding returning keys generated by the\n database when issuing update or insert statements.  Possible values :   KeyColumns.All  \u2014 all columns with generated keys will be returned  KeyColumns.None  \u2014 no columns with generated keys will be returned  KeyColumns.named(cols: String*)  \u2014 only columns listed by name will be returned   Default value :  KeyColumns.None     StatementOptions  is a case class and in its companion object there is  Default \ninstance of it with the default option values. You can use this instance to\ntweak only some of the options using built-in  copy  method:  conn . statement ( \n   sql \"insert into users(name) values ($name)\" , \n   Default . copy ( option1   =   value1 ,   option2   =   value2 )  )",
            "title": "Options"
        },
        {
            "location": "/scala/statements/#executing-statements",
            "text": "Once you have an  ExecutableStatement  instance, you can execute it in a couple\nof different ways. The method of execution controls in what shape you get the\nresults from the database. Paragraphs below describe methods of executing statements.",
            "title": "Executing statements"
        },
        {
            "location": "/scala/statements/#executing-for-a-result-set",
            "text": "Arguably the simplest method of execution that returns results is to execute\nstatement for a result set. To do this, use  ExecutableStatement 's executeForSet \nmethod that returns  Future  of ResultSet .  ResultSet  gives you access to the rows as well as to the metadata like warnings\nissued by the DB engine, columns metadata and count of rows affected by the statement.\nIt also implements  Traversable  trait providing a convenience method of traversing\nthrough the rows.  Executing for set is simple, but be aware that for bigger sets you may encounter OutOfMemoryError s. All results are stored in memory, there is no paging of any\nkind. If you want to avoid this sort of problems, consider streaming  the results.  For the documentation on how to work with the resulting rows see Result Rows  chapter.  def   selectUserAge ( name :   String ) :   Future [ ResultSet ]   =   { \n   conn . statement ( sql \"select age from users where name = $name\" ). executeForSet ()  }",
            "title": "Executing for a result set"
        },
        {
            "location": "/scala/statements/#streaming-results",
            "text": "To stream results from the database, use  ExecutableStatement 's stream \nmethod. This method returns RowPublisher \ninstance which implements reactive stream's Publisher \ninterface.  stream  method never throws exceptions \u2014 failures are reported by\nthe returned publisher.  Items published are rows represented by  Row  trait. For the documentation on how\nto work with the resulting rows see  Result Rows  chapter.  Here are a couple of things to know when working with streams:   statement execution is deferred until publisher is subscribed to,  a publisher can be subscribed to only once,  after  stream  method is invoked, connection is considered busy and can be used\n     for other queries only after the stream completes or is cancelled,  cancel is an asynchronous operation and Reactive Streams specification doesn't\n     provide a way of notifying a client that cancel operation completed. If clients\n     want to use the connection after stream cancellation, they must watch for\n     publisher's  done   Future  completion before requesting any\n     subsequent operations.   RowPublisher  instance, through its members, gives access to number\nof affected rows, warnings returned by the database and row metadata.  Processing streams is out of scope of this manual, for details please refer to\ndocumentation of Reactive Streams compatible libraries that are built to\nfacilitate this, like Akka stream  or Monix .  Examples (which release the connection on stream termination):  import   akka.stream.scaladsl. { Source ,   Sink }  import   akka.NotUsed  val   source :   Source [ Row ,  NotUsed ]   =   { \n   Source . fromPublisher ( \n     conn . statement ( sql \"select name from users\" ). stream () \n   ). alsoTo ( Sink . onComplete ( _   =>   conn . release ()))  }   import   monix.reactive.Observable  import   monix.eval.Task  val   obs :   Observable [ Row ]   =   { \n   Observable . fromReactivePublisher ( \n     conn . statement ( sql \"select name from users\" ). stream () \n   ). doOnTerminateEval ( _   =>   Task . fromFuture ( conn . release ()))  }",
            "title": "Streaming results"
        },
        {
            "location": "/scala/statements/#executing-ignoring-results",
            "text": "In many cases clients are not interested in any result of statement execution\nother than simple \"success\" or \"failure\" information. This is often the case\nfor  insert ,  update  and  delete  commands. This use case is covered by ExecutableStatement 's  execute  method which returns  Future  of  Unit .  Example:  def   insertUser ( name :   String ) :   Future [ Unit ]   =   { \n   conn . statement ( sql \"insert into users(name) values ($name)\" ). execute ()  }",
            "title": "Executing ignoring results"
        },
        {
            "location": "/scala/statements/#executing-for-a-single-row-and-for-a-value",
            "text": "It is a common use case to expect just a single row to be returned by a query.\nFor instance, when querying by a primary key. This can be easily achieved by\nusing  ExecutableStatement 's executeForFirstRow \nmethod which returns a  Future  of  Option[Row] . Returned  Option  is  None \nin case when query doesn't return any results, otherwise, the first row is\nreturned as a  Some .  Example:  def   findUser ( login :   String ) :   Future [ Option [ Row ]]   =   { \n   conn . statement ( sql \"select * from users where login = $login\" ) \n       . executeForFirstRow ()  }   Sometimes, not even a single row is needed by a client, only a single column\nvalue, like user's name when searching by login. executeForValue \nmethod comes in handy in these kind of situations. The method accepts  a function\nthat is supposed to extract this single value from a returned row, if any.  See the example below:  def   findUsersName ( login :   String ) :   Future [ Option [ String ]]   =   { \n   conn . statement ( sql \"select name from users where login = $login\" ) \n       . executeForValue ( r   =>   r . str ( \"name\" ))  }   For the documentation on how to work with the resulting rows see Result Rows  chapter.",
            "title": "Executing for a single row and for a value"
        },
        {
            "location": "/scala/statements/#executing-for-rows-affected",
            "text": "When executing insert, update or delete statements it may be good to know\nhow many rows were affected by the execution. A number of affected rows can be\nobtained when executing for set or by streaming but if it's the only information\nthat is needed use  ExecutableStatement 's  executeForRowsAffected \nmethod which returns a  Future  of  Long .  See the example below:  def   updateNames ( name :   String ,   age :   Int ) :   Future [ Long ]   =   { \n   conn . statement ( sql \"update users set name = $name where age = $age\" ) \n       . executeForRowsAffected ()  }",
            "title": "Executing for rows affected"
        },
        {
            "location": "/scala/statements/#executing-for-generated-key",
            "text": "If you rely on primary keys being generated by the database when inserting\nnew records you'll need just this one key as a result of the execution. If you\nneed to get multiple generated values then use  executeForStream ,  executeForSet \nor  executeForFirstRow  described above but for a single one, there is executeForKey \nmethod. This method executes a statement and returns the first column of the first\nreturned row (in most cases the result is going to be a single row with a single\ncolumn anyway). The method is parametrized by a type of the key.  A method in the example below inserts a new user and returns a generated UUID key.  def   insertUser ( name :   String ,   age :   Int ) :   Future [ UUID ]   =   { \n   conn . statement ( \n         sql \"insert into users(name, age) values($name, $age)\" , \n         StatementOptions . ReturnGenKeys \n   ). executeForKey [ UUID ]()  }",
            "title": "Executing for generated key"
        },
        {
            "location": "/scala/statements/#streaming-statement-arguments",
            "text": "rdbc provides an efficient way to execute statement repeatedly with many\nsets of arguments.  Statement  can subscribe to a stream of argument sets by\ninvoking  streamArgs  or  streamArgsByIdx  methods which accept Reactive Streams' Publisher . rdbc driver will back pressure the stream as needed.  Streaming arguments can be used for statements that don't return any values.\nTechnically it is possible to stream arguments of SQL  select s but there are no\nmeans for the client to get the data back from the database.",
            "title": "Streaming statement arguments"
        },
        {
            "location": "/scala/statements/#positional-and-named-parameters",
            "text": "Each stream element contains entire set of arguments that a given statement\nexpects. Clients have an alternative of using named and positional parameters: streamArgs  accepts a stream producing  Map [ String ,  Any ]  elements\n(named parameters) and  streamArgsByIdx  indexed sequences of arguments\n(positional parameters).",
            "title": "Positional and named parameters"
        },
        {
            "location": "/scala/statements/#handling-failures",
            "text": "If any error occurs in the middle of stream processing, the process will be aborted\nand  Future  returned by the streaming method will fail too.",
            "title": "Handling failures"
        },
        {
            "location": "/scala/statements/#examples",
            "text": "Creating  Publisher  instances is out of scope of this manual, for details please\nrefer to documentation of Reactive Streams compatible libraries that are built to\nfacilitate this, like Akka stream  or Monix . Examples below use simple streams backed by in\nmemory collections.  Streaming named arguments with Akka:  import   io.rdbc.sapi._  import   akka.stream.scaladsl.Source  val   res :   Future [ Unit ]   =   conn . withTransaction   { \n   val   data :   Vector [ Map [ String ,  Any ]]   =   Vector ( \n     Map ( \"name\"   ->   \"Robin\" ,   \"age\"   ->   10 ), \n     Map ( \"name\"   ->   \"Alex\" ,   \"age\"   ->   32 ), \n     Map ( \"name\"   ->   \"Casey\" ,   \"age\"   ->   12 ) \n   ) \n   val   publisher   =   Source ( data ). runWith ( Sink . asPublisher ( fanout   =   false )) \n   val   stmt   =   conn . statement ( \"insert into users(name, age) values (:name, :age)\" ) \n   stmt . streamArgs ( publisher )  }   Streaming positional arguments with Akka:  import   io.rdbc.sapi._  import   akka.stream.scaladsl.Source  val   res :   Future [ Unit ]   =   conn . withTransaction   { \n   val   data :   Vector [ Vector [ Any ]]   =   Vector ( \n     Vector ( \"Robin\" ,   10 ), \n     Vector ( \"Alex\" ,   32 ), \n     Vector ( \"Casey\" ,   12 ) \n   ) \n   val   publisher   =   Source ( data ). runWith ( Sink . asPublisher ( fanout   =   false )) \n   val   stmt   =   conn . statement ( \"insert into users(name, age) values (?, ?)\" ) \n   stmt . streamArgsByIdx ( publisher )  }",
            "title": "Examples"
        },
        {
            "location": "/scala/types/",
            "text": "Both when passing arguments to statements and when processing resulting rows\nthere is a need to convert values between database data types and Scala types.\nParagraphs below describe the mapping and possible conversions.\n\n\nType mapping\n\u00b6\n\n\nFollowing table lists mapping between Scala and SQL types.\n\n\n\n\n\n\n\n\nSQL type\n\n\nScala type\n\n\n\n\n\n\n\n\n\n\nCHAR\n\n\nString\n\n\n\n\n\n\nVARCHAR\n\n\nString\n\n\n\n\n\n\nNCHAR\n\n\nString\n\n\n\n\n\n\nNVARCHAR\n\n\nString\n\n\n\n\n\n\nCLOB\n\n\nString\n\n\n\n\n\n\nNCLOB\n\n\nString\n\n\n\n\n\n\nBINARY\n\n\nArray[Byte]\n\n\n\n\n\n\nVARBINARY\n\n\nArray[Byte]\n\n\n\n\n\n\nBLOB\n\n\nArray[Byte]\n\n\n\n\n\n\nBOOLEAN\n\n\nBoolean\n\n\n\n\n\n\nNUMERIC\n\n\nio.rdbc.sapi.DecimalNumber\n\n\n\n\n\n\nDECIMAL\n\n\nio.rdbc.sapi.DecimalNumber\n\n\n\n\n\n\nREAL\n\n\nFloat\n\n\n\n\n\n\nDOUBLE\n\n\nDouble\n\n\n\n\n\n\nSMALLINT\n\n\nInt\n\n\n\n\n\n\nINTEGER\n\n\nInt\n\n\n\n\n\n\nBIGINT\n\n\nLong\n\n\n\n\n\n\nDATE\n\n\njava.time.LocalDate\n\n\n\n\n\n\nTIME\n\n\njava.time.LocalTime\n\n\n\n\n\n\nTIMESTAMP\n\n\njava.time.LocalDateTime\n\n\n\n\n\n\nTIMESTAMP WITH TIME ZONE\n\n\njava.time.ZonedDateTime\n\n\n\n\n\n\n\n\nFollowing table lists mapping between Scala and database types not defined\nby the SQL standard.\n\n\n\n\n\n\n\n\nSQL type\n\n\nScala type\n\n\n\n\n\n\n\n\n\n\nUUID\n\n\njava.util.UUID\n\n\n\n\n\n\n\n\nResult type conversions\n\u00b6\n\n\nSQL types listed in \nType mapping\n paragraph can be represented \nnot only by their direct Scala counterparts. For example, NUMERIC can also be\nconverted to Scala's \nFloat\n. If user requests NUMERIC column value as a \nFloat\n,\n\nFloat\n will be returned, but only if the NUMERIC value is representable by\nexact \nFloat\n. The table below lists possible conversions.\n\n\n\n\n\n\n\n\nSource SQL type\n\n\nTarget Scala type\n\n\nNotes\n\n\n\n\n\n\n\n\n\n\nCHAR, NCHAR\n\n\nBoolean\n\n\n'1'\n, \n'T'\n, \n'Y'\n converts to \ntrue\n.\n'0'\n, \n'F'\n, \n'N'\n converts to \nfalse\n.\n\n\n\n\n\n\nDECIMAL, NUMERIC, REAL, DOUBLE, INTEGER, SMALLINT, BIGINT\n\n\nBoolean\n\n\n1 converts to \ntrue\n.\n0 converts to \nfalse\n.\n\n\n\n\n\n\nDECIMAL, NUMERIC, REAL, DOUBLE, INTEGER, SMALLINT, BIGINT\n\n\nFloat\n, \nDouble\n, \nByte\n, \nShort\n, \nInt\n, \nLong\n\n\nOnly if exact conversion is possible.\n\n\n\n\n\n\nINTEGER, SMALLINT, BIGINT\n\n\nBigDecimal\n\n\n\n\n\n\n\n\nDECIMAL, NUMERIC, REAL, DOUBLE\n\n\nBigDecimal\n\n\nInfinity and NaN are not convertible.\n\n\n\n\n\n\n\n\nIf client requests to convert between inconvertible types,\n\nConversionException\n\nis thrown.\n\n\nExplicitly setting database type in statements\n\u00b6\n\n\nrdbc defines a set of case classes that directly represent SQL types. When setting\nstatement arguments, in case when a given bare Scala type maps to more\nthan one database type (such as \nString\n maps to both \nCLOB\n and \nVARCHAR\n) and\nyou want to enforce this argument to be represented as a specific database type,\na case class representing SQL type can be used. \n\n\nFor example, if you want to pass \n\"my text\"\n as a \nCLOB\n, instead of passing bare \n\"my text\"\n, \npass \nio\n.\nrdbc\n.\nsapi\n.\nSqlClob\n(\n\"my text\"\n)\n.\n\n\nSetting typed SQL NULL values\n\u00b6\n\n\nNormally, to set a statement argument as \nNULL\n you can Scala's \nNone\n. \nNone\n\nvalue doesn't carry any information that would allow the rdbc driver to tell\nwhat is a SQL type of the \nNULL\n value. For most cases the type of the \nNULL\n\nvalue doesn't matter but in cases it does you can use rdbc's \nSqlNull\n that\ncontains the type information.\n\n\nFor example, to pass a \nNULL\n value typed as \nNVARCHAR\n, use \nSqlNull\n.\nof\n[\nSqlNVarchar\n]\n.\n\n\nVendor specific types\n\u00b6\n\n\nrdbc driver implementing support for a particular database vendor may provide\nadditional type mappings and conversions. Consult the driver's documentation\non this topic.",
            "title": "Data types"
        },
        {
            "location": "/scala/types/#type-mapping",
            "text": "Following table lists mapping between Scala and SQL types.     SQL type  Scala type      CHAR  String    VARCHAR  String    NCHAR  String    NVARCHAR  String    CLOB  String    NCLOB  String    BINARY  Array[Byte]    VARBINARY  Array[Byte]    BLOB  Array[Byte]    BOOLEAN  Boolean    NUMERIC  io.rdbc.sapi.DecimalNumber    DECIMAL  io.rdbc.sapi.DecimalNumber    REAL  Float    DOUBLE  Double    SMALLINT  Int    INTEGER  Int    BIGINT  Long    DATE  java.time.LocalDate    TIME  java.time.LocalTime    TIMESTAMP  java.time.LocalDateTime    TIMESTAMP WITH TIME ZONE  java.time.ZonedDateTime     Following table lists mapping between Scala and database types not defined\nby the SQL standard.     SQL type  Scala type      UUID  java.util.UUID",
            "title": "Type mapping"
        },
        {
            "location": "/scala/types/#result-type-conversions",
            "text": "SQL types listed in  Type mapping  paragraph can be represented \nnot only by their direct Scala counterparts. For example, NUMERIC can also be\nconverted to Scala's  Float . If user requests NUMERIC column value as a  Float , Float  will be returned, but only if the NUMERIC value is representable by\nexact  Float . The table below lists possible conversions.     Source SQL type  Target Scala type  Notes      CHAR, NCHAR  Boolean  '1' ,  'T' ,  'Y'  converts to  true . '0' ,  'F' ,  'N'  converts to  false .    DECIMAL, NUMERIC, REAL, DOUBLE, INTEGER, SMALLINT, BIGINT  Boolean  1 converts to  true . 0 converts to  false .    DECIMAL, NUMERIC, REAL, DOUBLE, INTEGER, SMALLINT, BIGINT  Float ,  Double ,  Byte ,  Short ,  Int ,  Long  Only if exact conversion is possible.    INTEGER, SMALLINT, BIGINT  BigDecimal     DECIMAL, NUMERIC, REAL, DOUBLE  BigDecimal  Infinity and NaN are not convertible.     If client requests to convert between inconvertible types, ConversionException \nis thrown.",
            "title": "Result type conversions"
        },
        {
            "location": "/scala/types/#explicitly-setting-database-type-in-statements",
            "text": "rdbc defines a set of case classes that directly represent SQL types. When setting\nstatement arguments, in case when a given bare Scala type maps to more\nthan one database type (such as  String  maps to both  CLOB  and  VARCHAR ) and\nyou want to enforce this argument to be represented as a specific database type,\na case class representing SQL type can be used.   For example, if you want to pass  \"my text\"  as a  CLOB , instead of passing bare  \"my text\" , \npass  io . rdbc . sapi . SqlClob ( \"my text\" ) .",
            "title": "Explicitly setting database type in statements"
        },
        {
            "location": "/scala/types/#setting-typed-sql-null-values",
            "text": "Normally, to set a statement argument as  NULL  you can Scala's  None .  None \nvalue doesn't carry any information that would allow the rdbc driver to tell\nwhat is a SQL type of the  NULL  value. For most cases the type of the  NULL \nvalue doesn't matter but in cases it does you can use rdbc's  SqlNull  that\ncontains the type information.  For example, to pass a  NULL  value typed as  NVARCHAR , use  SqlNull . of [ SqlNVarchar ] .",
            "title": "Setting typed SQL NULL values"
        },
        {
            "location": "/scala/types/#vendor-specific-types",
            "text": "rdbc driver implementing support for a particular database vendor may provide\nadditional type mappings and conversions. Consult the driver's documentation\non this topic.",
            "title": "Vendor specific types"
        },
        {
            "location": "/scala/rows/",
            "text": "Statement rows are represented in rdbc as\n\nRow\n trait. This chapter describes\nthis trait and methods it provides that give access column values.\n\n\nGeneric methods\n\u00b6\n\n\nRow\n trait declares a family of \ncol\n methods that allow accessing column\nvalues of any Scala type. The methods accept a single type parameter telling\nrdbc what Scala type should be used to represent a database value \u2014 see\nthe list below for their simplified declarations.\n\n\n\n\ndef\n \ncol\n[\nA\n](\nidx\n:\n \nInt\n)\n:\n \nA\n\n\ndef\n \ncolOpt\n[\nA\n](\nidx\n:\n \nInt\n)\n:\n \nOption\n[\nA\n]\n\n\ndef\n \ncol\n[\nA\n](\nname\n:\n \nString\n)\n:\n \nA\n\n\ndef\n \ncolOpt\n[\nA\n](\nname\n:\n \nString\n)\n:\n \nOption\n[\nA\n]\n\n\n\n\nThe methods differ from one another in two areas:\n\n\n\n\n\n\nNamed vs unnamed columns\n\n\nTo fetch column value by name use method that accepts a \nString\n;\n to fetch value by column's index, use the version that accepts an \nInt\n.\n Index is 0 based.\n\n\n\n\n\n\nNull-safety\n\n\ncolOpt\n methods are null-safe, and \ncol\n methods aren't. You can't use\n plain \ncol\n method to get SQL \nNULL\n values. If you try that,\n \nConversionException\n\n will be thrown. \ncolOpt\n returns \nOption\n so it's fit for handling \nNULL\ns\n \u2014 it represents them by \nNone\n. \ncol\n method is intended to be used\n only for columns that can't hold \nNULL\n values, for example because there is\n a not-null constraint defined for them.\n\n\n\n\n\n\nExamples below show how to use \ncol\n methods on rows produced by \n\n\nselect\n \nfirst_name\n,\n \nlast_name\n,\n \nage\n \nfrom\n \npersons\n\n\n\n\n\n\nstatement.\n\n\n/* fetches first_name. If value is NULL ConversionException will be thrown */\n\n\nrow\n.\ncol\n[\nString\n](\n0\n)\n \n\n\n/* fetches last_name. If value is NULL ConversionException will be thrown */\n\n\nrow\n.\ncol\n[\nString\n](\n\"last_name\"\n)\n\n\n\n/* fetches age. If value is NULL, None will be returned */\n\n\nrow\n.\ncolOpt\n[\nInt\n](\n2\n)\n\n\n\n\n\n\nType-specific methods\n\u00b6\n\n\nRow\n trait, for convenience, also provides methods that aren't parametrized\nby type and their names reflect the type they return. They are simply shortcuts\nfor calling generic \ncol\n methods described earlier. For instance, there is a\n\nstr\n method that is a shortcut for calling \ncol[String]\n method. See the \n\nRow\n Scaladoc\n for a complete list.\n\n\nPrevious example could be rewritten as follows:\n\n\n/* fetches first_name. If value is NULL ConversionException will be thrown */\n\n\nrow\n.\nstr\n(\n0\n)\n \n\n\n/* fetches last_name. If value is NULL ConversionException will be thrown */\n\n\nrow\n.\nstr\n(\n\"last_name\"\n)\n\n\n\n/* fetches age. If value is NULL, None will be returned */\n\n\nrow\n.\nintOpt\n(\n2\n)\n\n\n\n\n\n\nIf you want to use types supported by the particular driver but not supported\nby default by rdbc, you must always use generic \ncol\n methods.",
            "title": "Result Rows"
        },
        {
            "location": "/scala/rows/#generic-methods",
            "text": "Row  trait declares a family of  col  methods that allow accessing column\nvalues of any Scala type. The methods accept a single type parameter telling\nrdbc what Scala type should be used to represent a database value \u2014 see\nthe list below for their simplified declarations.   def   col [ A ]( idx :   Int ) :   A  def   colOpt [ A ]( idx :   Int ) :   Option [ A ]  def   col [ A ]( name :   String ) :   A  def   colOpt [ A ]( name :   String ) :   Option [ A ]   The methods differ from one another in two areas:    Named vs unnamed columns  To fetch column value by name use method that accepts a  String ;\n to fetch value by column's index, use the version that accepts an  Int .\n Index is 0 based.    Null-safety  colOpt  methods are null-safe, and  col  methods aren't. You can't use\n plain  col  method to get SQL  NULL  values. If you try that,\n  ConversionException \n will be thrown.  colOpt  returns  Option  so it's fit for handling  NULL s\n \u2014 it represents them by  None .  col  method is intended to be used\n only for columns that can't hold  NULL  values, for example because there is\n a not-null constraint defined for them.    Examples below show how to use  col  methods on rows produced by   select   first_name ,   last_name ,   age   from   persons   statement.  /* fetches first_name. If value is NULL ConversionException will be thrown */  row . col [ String ]( 0 )   /* fetches last_name. If value is NULL ConversionException will be thrown */  row . col [ String ]( \"last_name\" )  /* fetches age. If value is NULL, None will be returned */  row . colOpt [ Int ]( 2 )",
            "title": "Generic methods"
        },
        {
            "location": "/scala/rows/#type-specific-methods",
            "text": "Row  trait, for convenience, also provides methods that aren't parametrized\nby type and their names reflect the type they return. They are simply shortcuts\nfor calling generic  col  methods described earlier. For instance, there is a str  method that is a shortcut for calling  col[String]  method. See the  Row  Scaladoc  for a complete list.  Previous example could be rewritten as follows:  /* fetches first_name. If value is NULL ConversionException will be thrown */  row . str ( 0 )   /* fetches last_name. If value is NULL ConversionException will be thrown */  row . str ( \"last_name\" )  /* fetches age. If value is NULL, None will be returned */  row . intOpt ( 2 )   If you want to use types supported by the particular driver but not supported\nby default by rdbc, you must always use generic  col  methods.",
            "title": "Type-specific methods"
        },
        {
            "location": "/scala/faq/",
            "text": "Here are some questions that have a potential to become frequently asked.\n\n\n\n\n\n\nI have plenty of time, I don't want to use any timeout for any of my queries. What can I do?\n\n\nDeclare implicit \nTimeout\n instance of infinite duration \u2014 \nio.rdbc.sapi.Timeout.Inf\n.\n\n\n\n\n\n\n\n\nHow do I build SQL dynamically using \nsql\n interpolator?\n\n\nUse special \n#$\n prefix for the dynamic parts. See \nthis\n\n  paragraph for details.\n\n\n\n\n\n\n\n\nHow to pass \nTimeout\n explicitly to \nExecutableStatement\n's \nexecuteForKey\n method? I keep getting compilation errors.\n\n\nexecuteForKey\n method's declaration is\n\n\ndef\n \nexecuteForKey\n[\nK:\n \nClassTag\n]()(\nimplicit\n \ntimeout\n:\n \nTimeout\n)\n:\n \nFuture\n[\nK\n]\n\n\n\n\n\n\nUnder the hood, this declaration really means this:\n\n\ndef\n \nexecuteForKey\n[\nK\n]()(\nimplicit\n \nclassTag\n:\n \nClassTag\n[\nK\n],\n \ntimeout\n:\n \nTimeout\n)\n:\n \nFuture\n[\nK\n]\n\n\n\n\n\n\nSo you can't really execute this method like this: \n\n\nexecuteForKey\n[\nInt\n]()(\ntimeout\n)\n\n\n\n\n\n\nInstead, you have to do this:\n\n\nexecuteForKey\n()(\ntimeout\n,\n \nclassOf\n[\nInt\n])\n\n\n\n\n\n\n\n\n\n\n\n\nI'm executing insert statement and trying to get auto-generated key from the DB but nothing is returned. What am I doing wrong?\n\n\nYou probably forgot to set a \ngeneratedKeyCols\n statement option accordingly.\n  See \nthis\n paragraph for details.",
            "title": "FAQ"
        },
        {
            "location": "/java/java/",
            "text": "Java API is available but not yet documented.",
            "title": "Java API user guide"
        },
        {
            "location": "/drivers/",
            "text": "Even though this documentation is database vendor-agnostic, for reader's\nconvenience the list below contains information about available rdbc driver\nimplementations categorized by a database vendor.\n\n\nYes, the documentation author is aware that the list currently contains only one item.\n\n\nPostgreSQL\n\u00b6\n\n\n\n\n\n\nrdbc-pgsql\n\n\nNetty-based PostgreSQL rdbc driver.\n\n\nWebsite: \nhttps://github.com/rdbc-io/rdbc-pgsql",
            "title": "Drivers"
        },
        {
            "location": "/drivers/#postgresql",
            "text": "rdbc-pgsql  Netty-based PostgreSQL rdbc driver.  Website:  https://github.com/rdbc-io/rdbc-pgsql",
            "title": "PostgreSQL"
        },
        {
            "location": "/examples/",
            "text": "Example projects are implemented in\n\nrdbc-io/rdbc-examples\n\nGitHub repository. For detailed description of these samples see the repository's\nREADME.",
            "title": "Examples"
        }
    ]
}